"""
DeepDive AI Service - FastAPI åº”ç”¨å…¥å£
"""
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from loguru import logger
import sys
import os

# âš ï¸ å…³é”®ï¼šå¿…é¡»åœ¨å¯¼å…¥ secret_manager ä¹‹å‰åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# Import routers
from routers import ai, report, workspace, quick_generate
from services.grok_client import GrokClient
from services.openai_client import OpenAIClient
from services.ai_orchestrator import AIOrchestrator
from utils.secret_manager import secret_manager
from utils.feature_flags import is_workspace_ai_v2_enabled

# é…ç½®æ—¥å¿—
logger.remove()
# Windows ç¯å¢ƒä¸‹é…ç½® UTF-8 è¾“å‡ºä»¥æ”¯æŒ emoji
import io
import platform
if platform.system() == "Windows":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>",
    level="INFO"
)

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="DeepDive AI Service",
    description="AI-driven insights and content processing service",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# é…ç½® CORS - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ‰€æœ‰localhostç«¯å£
app.add_middleware(
    CORSMiddleware,
    allow_origin_regex=r"http://localhost:\d+",  # å…è®¸æ‰€æœ‰localhostç«¯å£
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH"],
    allow_headers=["*"],
    expose_headers=["*"],
    max_age=3600,  # OPTIONSé¢„æ£€ç¼“å­˜æ—¶é—´
)

# åˆå§‹åŒ– AI å®¢æˆ·ç«¯
grok_api_key = secret_manager.get_grok_api_key()
openai_api_key = secret_manager.get_openai_api_key()

grok_client = GrokClient(api_key=grok_api_key)
openai_client = OpenAIClient(api_key=openai_api_key)

# åˆå§‹åŒ–ç¼–æ’å™¨ï¼ˆå…¨å±€å•ä¾‹ï¼‰
orchestrator = AIOrchestrator(grok_client, openai_client)

# æ³¨å†Œè·¯ç”±
app.include_router(ai.router, prefix="/api/v1")
app.include_router(report.router)
app.include_router(workspace.router, prefix="/api/v1")
app.include_router(quick_generate.router)

# å°†AIå®¢æˆ·ç«¯æ³¨å…¥åˆ°reportè·¯ç”±ä¸­
report.init_clients(grok_client, openai_client)
quick_generate.init_clients(grok_client, openai_client)


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "DeepDive AI Service",
        "version": "1.0.0",
        "status": "running",
        "workspaceAiV2Enabled": is_workspace_ai_v2_enabled(),
    }


@app.get("/api/v1")
async def api_root():
    """API æ ¹è·¯å¾„"""
    return {
        "message": "DeepDive AI Service API v1",
        "endpoints": {
            "summary": "/api/v1/ai/summary",
            "insights": "/api/v1/ai/insights",
            "classify": "/api/v1/ai/classify",
            "health": "/api/v1/ai/health"
        }
    }


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    logger.info("ğŸš€ DeepDive AI Service starting up...")
    logger.info(f"ğŸ“ Grok available: {grok_client.available}")
    logger.info(f"ğŸ“ OpenAI available: {openai_client.available}")
    logger.info(f"ğŸ¯ Active model: {orchestrator.active_model}")
    logger.info(f"ğŸ§© Workspace AI v2 enabled: {is_workspace_ai_v2_enabled()}")


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­äº‹ä»¶"""
    logger.info("ğŸ‘‹ DeepDive AI Service shutting down...")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=int(os.environ.get("PORT", 8000)),
        
        log_level="info"
    )
