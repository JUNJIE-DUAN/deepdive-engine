"""
æŠ¥å‘Šç”Ÿæˆè·¯ç”± - å¤šç´ æAIç»¼åˆæŠ¥å‘Š
"""
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
import json
import logging

router = APIRouter()
logger = logging.getLogger(__name__)

# AIå®¢æˆ·ç«¯å°†ä»main.pyå¯¼å…¥
grok_client = None
openai_client = None


def init_clients(grok, openai):
    """
    åˆå§‹åŒ–AIå®¢æˆ·ç«¯ï¼ˆä»main.pyæ³¨å…¥ï¼‰

    Args:
        grok: GrokClientå®ä¾‹
        openai: OpenAIClientå®ä¾‹
    """
    global grok_client, openai_client
    grok_client = grok
    openai_client = openai
    logger.info("Report router: AI clients initialized")


class Resource(BaseModel):
    """èµ„æºæ¨¡å‹"""
    id: str
    title: str
    abstract: Optional[str] = None
    authors: Optional[Any] = None
    published_date: Optional[str] = None
    tags: Optional[Any] = None
    type: str


class ReportRequest(BaseModel):
    """æŠ¥å‘Šç”Ÿæˆè¯·æ±‚"""
    resources: List[Resource] = Field(..., min_items=2, max_items=10)
    template: str = Field(..., pattern="^(comparison|trend|learning-path|literature-review)$")
    model: str = Field(default="grok", pattern="^(grok|gpt-4)$")


class ReportSection(BaseModel):
    """æŠ¥å‘Šç« èŠ‚"""
    title: str
    content: str


class ReportResponse(BaseModel):
    """æŠ¥å‘Šå“åº”"""
    title: str
    summary: str
    sections: List[ReportSection]
    metadata: Optional[Dict[str, Any]] = None


def prepare_resources_info(resources: List[Resource]) -> str:
    """å‡†å¤‡èµ„æºä¿¡æ¯æ–‡æœ¬"""
    info_parts = []
    for i, resource in enumerate(resources, 1):
        # å¤„ç†authors
        authors_str = "N/A"
        if resource.authors:
            if isinstance(resource.authors, list):
                # å¤„ç†dictæˆ–stringåˆ—è¡¨
                author_names = []
                for author in resource.authors[:3]:
                    if isinstance(author, dict):
                        # å°è¯•ä»dictä¸­æå–nameå­—æ®µ
                        author_names.append(author.get('name', author.get('id', str(author))))
                    elif isinstance(author, str):
                        author_names.append(author)
                authors_str = ", ".join(author_names) if author_names else "N/A"
            elif isinstance(resource.authors, str):
                authors_str = resource.authors

        # å¤„ç†tags
        tags_str = "N/A"
        if resource.tags:
            if isinstance(resource.tags, list):
                tags_str = ", ".join(resource.tags[:5])  # åªæ˜¾ç¤ºå‰5ä¸ªæ ‡ç­¾
            elif isinstance(resource.tags, str):
                tags_str = resource.tags

        # å¤„ç†abstract
        abstract = resource.abstract or "No abstract available"
        if len(abstract) > 500:
            abstract = abstract[:500] + "..."

        info = f"""
Resource {i}:
- ID: {resource.id}
- Title: {resource.title}
- Type: {resource.type}
- Date: {resource.published_date or 'N/A'}
- Authors: {authors_str}
- Tags: {tags_str}
- Abstract: {abstract}
"""
        info_parts.append(info)

    return "\n".join(info_parts)


# æŠ¥å‘Šæ¨¡æ¿Prompts
REPORT_PROMPTS = {
    "comparison": """You are a technical analyst. Analyze and compare the following {count} resources.

Resources:
{resources_info}

Generate a comprehensive comparison report with these sections:

1. **Executive Summary** (200-300 words)
   - Overview of all resources
   - Main themes and connections
   - Key takeaways

2. **Detailed Comparison**
   Create a comparison table in markdown format with these aspects:
   - Approach/Method
   - Key Innovation
   - Performance/Results
   - Limitations
   - Use Cases

3. **Key Insights** (5-7 bullet points)
   - Common patterns across resources
   - Key differences and trade-offs
   - Evolution and improvements
   - Complementary aspects

4. **Recommendations**
   - Which to choose for different scenarios
   - Learning order suggestions
   - Further reading

IMPORTANT: Output ONLY valid JSON in this exact format:
{{
  "title": "Comparison of [Topic]",
  "summary": "Executive summary text...",
  "sections": [
    {{"title": "Detailed Comparison", "content": "markdown table and text"}},
    {{"title": "Key Insights", "content": "markdown list"}},
    {{"title": "Recommendations", "content": "markdown text"}}
  ]
}}

JSON output:
""",

    "trend": """You are a technology trend analyst. Analyze the following {count} resources to identify trends.

Resources:
{resources_info}

Generate a trend analysis report with these sections:

1. **Overview** (150-200 words)
   - Time span covered
   - Main themes
   - Overall direction

2. **Technology Timeline**
   Create a chronological timeline in markdown format showing:
   - Year/Date
   - Key milestone
   - Innovation introduced
   - Impact level (High/Medium/Low)

3. **Key Breakthroughs** (4-6 items)
   For each breakthrough:
   - What changed
   - Why it matters
   - Follow-up work

4. **Trend Predictions**
   - Emerging patterns
   - Likely next developments (3-6 months)
   - Opportunities and challenges

IMPORTANT: Output ONLY valid JSON in this exact format:
{{
  "title": "Trend Analysis: [Topic]",
  "summary": "Overview text...",
  "sections": [
    {{"title": "Technology Timeline", "content": "markdown timeline"}},
    {{"title": "Key Breakthroughs", "content": "markdown list"}},
    {{"title": "Trend Predictions", "content": "markdown text"}}
  ]
}}

JSON output:
""",

    "learning-path": """You are a learning path designer. Create a structured learning plan from these {count} resources.

Resources:
{resources_info}

Generate a learning path report with these sections:

1. **Learning Objectives** (150 words)
   - What you'll learn
   - Target audience
   - Prerequisites

2. **Recommended Learning Sequence**
   For each resource (in order):
   - Resource title and type
   - Difficulty level (Beginner/Intermediate/Advanced)
   - Estimated time investment
   - Key concepts covered
   - Why this sequence matters

3. **Difficulty Analysis**
   - Concept progression
   - Knowledge dependencies
   - Potential challenges

4. **Practice Recommendations**
   - Hands-on projects
   - Additional resources
   - Learning tips

IMPORTANT: Output ONLY valid JSON in this exact format:
{{
  "title": "Learning Path: [Topic]",
  "summary": "Learning objectives text...",
  "sections": [
    {{"title": "Recommended Learning Sequence", "content": "markdown ordered list"}},
    {{"title": "Difficulty Analysis", "content": "markdown text"}},
    {{"title": "Practice Recommendations", "content": "markdown list"}}
  ]
}}

JSON output:
""",

    "literature-review": """You are an academic researcher. Write a literature review for these {count} resources.

Resources:
{resources_info}

Generate an academic literature review with these sections:

1. **Introduction and Background** (200-250 words)
   - Research context
   - Motivation and significance
   - Scope of review

2. **Methodology Evolution**
   Discuss how methods have evolved:
   - Early approaches
   - Key innovations
   - Current state-of-the-art

3. **Comparative Analysis**
   Create a detailed comparison of:
   - Research methods
   - Results and findings
   - Strengths and limitations

4. **Future Directions**
   - Open problems
   - Promising research directions
   - Potential applications

IMPORTANT: Output ONLY valid JSON in this exact format:
{{
  "title": "Literature Review: [Topic]",
  "summary": "Introduction text...",
  "sections": [
    {{"title": "Methodology Evolution", "content": "markdown text"}},
    {{"title": "Comparative Analysis", "content": "markdown text with tables"}},
    {{"title": "Future Directions", "content": "markdown list"}}
  ]
}}

JSON output:
"""
}


def parse_json_response(response_text: str) -> Dict[str, Any]:
    """è§£æAIå“åº”ä¸­çš„JSON"""
    try:
        # å°è¯•ç›´æ¥è§£æ
        return json.loads(response_text)
    except json.JSONDecodeError:
        # å°è¯•æå–JSONéƒ¨åˆ†
        response_text = response_text.strip()

        # ç§»é™¤markdownä»£ç å—
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()

        # æŸ¥æ‰¾JSONå¯¹è±¡
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}')

        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            json_str = response_text[start_idx:end_idx + 1]
            try:
                return json.loads(json_str)
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse JSON: {e}\nContent: {json_str[:200]}")
                raise

        raise ValueError("No valid JSON found in response")


@router.post("/api/v1/ai/generate-report", response_model=ReportResponse)
async def generate_report(request: ReportRequest):
    """
    ç”Ÿæˆå¤šç´ æç»¼åˆæŠ¥å‘Š

    Args:
        request: åŒ…å«èµ„æºåˆ—è¡¨ã€æ¨¡æ¿å’Œæ¨¡å‹çš„è¯·æ±‚

    Returns:
        ReportResponse: ç»“æ„åŒ–çš„æŠ¥å‘Šå†…å®¹
    """
    try:
        logger.info(f"Generating {request.template} report for {len(request.resources)} resources using {request.model}")

        # 1. å‡†å¤‡èµ„æºä¿¡æ¯
        resources_info = prepare_resources_info(request.resources)

        # 2. é€‰æ‹©promptæ¨¡æ¿
        prompt_template = REPORT_PROMPTS.get(request.template)
        if not prompt_template:
            raise HTTPException(status_code=400, detail=f"Invalid template: {request.template}")

        # 3. æ„å»ºå®Œæ•´prompt
        prompt = prompt_template.format(
            count=len(request.resources),
            resources_info=resources_info
        )

        # 4. è°ƒç”¨AIç”Ÿæˆ
        if request.model == "gpt-4":
            logger.info("Using OpenAI GPT-4")
            response = await openai_client.chat(
                messages=[{
                    "role": "system",
                    "content": "You are a helpful AI assistant that generates structured reports. Always output valid JSON."
                }, {
                    "role": "user",
                    "content": prompt
                }],
                model="gpt-4",
                temperature=0.7,
                max_tokens=3000
            )
        else:
            logger.info("Using Grok")
            response = await grok_client.chat(
                messages=[{
                    "role": "system",
                    "content": "You are a helpful AI assistant that generates structured reports. Always output valid JSON."
                }, {
                    "role": "user",
                    "content": prompt
                }],
                temperature=0.7,
                max_tokens=3000
            )

        # 5. è§£æå“åº”
        report_data = parse_json_response(response)

        # 6. éªŒè¯å¿…éœ€å­—æ®µ
        if "title" not in report_data or "summary" not in report_data or "sections" not in report_data:
            raise ValueError("Response missing required fields: title, summary, or sections")

        # 7. æ„å»ºå“åº”
        result = ReportResponse(
            title=report_data["title"],
            summary=report_data["summary"],
            sections=[
                ReportSection(title=s["title"], content=s["content"])
                for s in report_data["sections"]
            ],
            metadata={
                "model": request.model,
                "template": request.template,
                "resourceCount": len(request.resources),
            }
        )

        logger.info(f"Successfully generated report: {result.title}")
        return result

    except json.JSONDecodeError as e:
        logger.error(f"JSON parsing error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to parse AI response as JSON: {str(e)}"
        )
    except Exception as e:
        logger.error(f"Report generation error: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Failed to generate report: {str(e)}"
        )


@router.get("/api/v1/ai/report-templates")
async def get_report_templates():
    """è·å–å¯ç”¨çš„æŠ¥å‘Šæ¨¡æ¿åˆ—è¡¨"""
    return {
        "templates": [
            {
                "id": "comparison",
                "name": "å¯¹æ¯”åˆ†æ",
                "description": "å¤šç»´åº¦å¯¹æ¯”å„ç´ æçš„ç‰¹ç‚¹ã€ä¼˜åŠ£åŠ¿å’Œé€‚ç”¨åœºæ™¯",
                "icon": "ğŸ“Š",
                "minItems": 2,
                "maxItems": 5,
                "estimatedTime": "60ç§’",
                "model": "gpt-4",
            },
            {
                "id": "trend",
                "name": "è¶‹åŠ¿æŠ¥å‘Š",
                "description": "åˆ†ææŠ€æœ¯æ¼”è¿›è½¨è¿¹å’Œæœªæ¥å‘å±•æ–¹å‘",
                "icon": "ğŸ“ˆ",
                "minItems": 3,
                "maxItems": 10,
                "estimatedTime": "45ç§’",
                "model": "grok",
            },
            {
                "id": "learning-path",
                "name": "å­¦ä¹ è·¯å¾„",
                "description": "ç”Ÿæˆç”±æµ…å…¥æ·±çš„å­¦ä¹ è®¡åˆ’å’Œå®è·µå»ºè®®",
                "icon": "ğŸ—ºï¸",
                "minItems": 3,
                "maxItems": 8,
                "estimatedTime": "50ç§’",
                "model": "grok",
            },
            {
                "id": "literature-review",
                "name": "æ–‡çŒ®ç»¼è¿°",
                "description": "å­¦æœ¯é£æ ¼çš„æ–‡çŒ®ç»¼è¿°æŠ¥å‘Š",
                "icon": "ğŸ“",
                "minItems": 5,
                "maxItems": 10,
                "estimatedTime": "90ç§’",
                "model": "gpt-4",
            },
        ]
    }


class ChatRequest(BaseModel):
    """èµ„æºå¯¹è¯è¯·æ±‚"""
    resources: List[Resource] = Field(..., min_items=1, max_items=10)
    message: str = Field(..., min_length=1)
    history: List[Dict[str, str]] = Field(default_factory=list)
    model: str = Field(default="grok", pattern="^(grok|gpt-4)$")


class ChatResponse(BaseModel):
    """å¯¹è¯å“åº”"""
    message: str


@router.post("/api/v1/ai/chat", response_model=ChatResponse)
async def chat_with_resources(request: ChatRequest):
    """
    ä¸èµ„æºè¿›è¡Œå¯¹è¯ï¼ŒåŸºäºèµ„æºå†…å®¹å›ç­”é—®é¢˜

    Args:
        request: åŒ…å«èµ„æºåˆ—è¡¨ã€ç”¨æˆ·æ¶ˆæ¯å’Œå¯¹è¯å†å²

    Returns:
        ChatResponse: AIçš„å›ç­”
    """
    try:
        logger.info(f"Chat request for {len(request.resources)} resources using {request.model}")

        # 1. å‡†å¤‡èµ„æºä¿¡æ¯ä¸Šä¸‹æ–‡
        resources_context = prepare_resources_info(request.resources)

        # 2. æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶åŠ©æ‰‹ã€‚ç”¨æˆ·é€‰æ‹©äº†ä»¥ä¸‹èµ„æºï¼Œä½ éœ€è¦åŸºäºè¿™äº›èµ„æºçš„å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

èµ„æºä¿¡æ¯ï¼š
{resources_context}

è¯·åŸºäºä»¥ä¸Šèµ„æºå†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœé—®é¢˜æ¶‰åŠèµ„æºä¸­æ²¡æœ‰çš„ä¿¡æ¯ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚å›ç­”è¦å‡†ç¡®ã€ä¸“ä¸šã€æœ‰æ¡ç†ã€‚"""

        # 3. æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [{"role": "system", "content": system_prompt}]

        # æ·»åŠ å†å²å¯¹è¯ï¼ˆæœ€å¤šä¿ç•™æœ€è¿‘5è½®ï¼‰
        for h in request.history[-10:]:  # æœ€å¤š10æ¡å†å²æ¶ˆæ¯
            messages.append(h)

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": request.message})

        # 4. è°ƒç”¨AIç”Ÿæˆå“åº”
        if request.model == "gpt-4":
            logger.info("Using OpenAI GPT-4")
            response = await openai_client.chat(
                messages=messages,
                model="gpt-4",
                temperature=0.7,
                max_tokens=1500
            )
        else:
            logger.info("Using Grok")
            response = await grok_client.chat(
                messages=messages,
                temperature=0.7,
                max_tokens=1500
            )

        if response is None:
            raise HTTPException(
                status_code=503,
                detail="AI service unavailable"
            )

        logger.info(f"Chat response generated: {len(response)} characters")
        return ChatResponse(message=response)

    except Exception as e:
        logger.error(f"Chat error: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"å¯¹è¯å¤±è´¥: {str(e)}"
        )


# YouTubeæŠ¥å‘Šç›¸å…³æ¨¡å‹
class YoutubeReportRequest(BaseModel):
    """YouTubeæŠ¥å‘Šç”Ÿæˆè¯·æ±‚"""
    title: str
    transcript: str
    model: str = Field(default="gpt-4", pattern="^(grok|gpt-4)$")


class TranscriptLine(BaseModel):
    """å­—å¹•è¡Œ"""
    english: str
    chinese: str


class YoutubeReportResponse(BaseModel):
    """YouTubeæŠ¥å‘Šå“åº”"""
    title: str
    summary: str
    translations: List[TranscriptLine]


@router.post("/youtube-report", response_model=YoutubeReportResponse)
async def generate_youtube_report(request: YoutubeReportRequest):
    """
    ç”ŸæˆYouTubeè§†é¢‘å­—å¹•æŠ¥å‘Šï¼ˆå«é€å¥ä¸­è‹±ç¿»è¯‘ï¼‰
    """
    try:
        logger.info(f"Generating YouTube report for: {request.title}")

        # é€‰æ‹©AIå®¢æˆ·ç«¯
        ai_client = openai_client if request.model == "gpt-4" else grok_client

        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ¦‚è¦
        summary_prompt = f"""
è¯·ä¸ºä»¥ä¸‹YouTubeè§†é¢‘ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ¦‚è¦ï¼ˆ200-300å­—ï¼‰ï¼ŒåŒ…æ‹¬ï¼š
1. è§†é¢‘ä¸»è¦å†…å®¹
2. æ ¸å¿ƒè§‚ç‚¹
3. å…³é”®ä¿¡æ¯

è§†é¢‘æ ‡é¢˜ï¼š{request.title}
è§†é¢‘å­—å¹•ï¼š
{request.transcript}

è¯·ç›´æ¥è¿”å›æ¦‚è¦æ–‡æœ¬ï¼Œä¸éœ€è¦å…¶ä»–æ ¼å¼ã€‚
"""

        logger.info("Step 1: Generating summary...")
        summary_response = await ai_client.chat_completion(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æå¸ˆã€‚"},
                {"role": "user", "content": summary_prompt}
            ]
        )

        summary = summary_response.get("content", "")
        logger.info(f"Summary generated: {len(summary)} characters")

        # ç¬¬äºŒæ­¥ï¼šå°†å­—å¹•åˆ†å¥å¹¶ç¿»è¯‘
        # ç®€åŒ–ï¼šä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ–‡æœ¬ï¼Œä½†é™åˆ¶æœ€å¤§é•¿åº¦
        transcript_text = request.transcript[:6000]  # é™åˆ¶æœ€å¤§é•¿åº¦é¿å…tokenè¶…é™

        translation_prompt = f"""
è¯·å°†ä»¥ä¸‹è‹±æ–‡å­—å¹•æŒ‰å¥ç¿»è¯‘æˆä¸­æ–‡ã€‚

è¦æ±‚ï¼š
1. æŒ‰è¯­ä¹‰å®Œæ•´æ€§åˆ†å¥ï¼ˆæ¯å¥2-3è¡Œå·¦å³ï¼‰
2. æ¯å¥è‹±æ–‡å¯¹åº”ä¸€å¥ä¸­æ–‡ç¿»è¯‘
3. ç¿»è¯‘è¦å‡†ç¡®ã€æµç•…ã€åœ°é“
4. ç¡®ä¿ALLå¥å­éƒ½æœ‰ç¿»è¯‘ï¼Œä¸è¦é—æ¼
5. è¿”å›JSONæ ¼å¼

æ ¼å¼ï¼š
{{
  "translations": [
    {{"english": "First sentence here.", "chinese": "ç¬¬ä¸€å¥çš„ä¸­æ–‡ç¿»è¯‘ã€‚"}},
    {{"english": "Second sentence here.", "chinese": "ç¬¬äºŒå¥çš„ä¸­æ–‡ç¿»è¯‘ã€‚"}}
  ]
}}

è‹±æ–‡å­—å¹•ï¼š
{transcript_text}

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ markdownæ ‡è®°ã€‚
"""

        logger.info("Step 2: Generating translations...")
        translation_response = await ai_client.chat_completion(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„è‹±ä¸­ç¿»è¯‘ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›å®Œæ•´çš„ç¿»è¯‘ç»“æœã€‚"},
                {"role": "user", "content": translation_prompt}
            ]
        )

        # è§£æç¿»è¯‘ç»“æœ
        translation_content = translation_response.get("content", "")
        logger.info(f"Translation response: {len(translation_content)} characters")

        # æ¸…ç†å¹¶è§£æJSON
        try:
            # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            clean_content = translation_content.strip()
            if clean_content.startswith("```"):
                lines = clean_content.split("\n")
                clean_content = "\n".join(lines[1:-1]) if len(lines) > 2 else clean_content
                clean_content = clean_content.replace("```json", "").replace("```", "").strip()

            translation_data = json.loads(clean_content)
            translations = translation_data.get("translations", [])

            if not translations:
                raise ValueError("No translations found in response")

            logger.info(f"Successfully parsed {len(translations)} translation pairs")

        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Failed to parse translations: {e}")
            logger.error(f"Raw content: {translation_content[:1000]}")

            # é™çº§å¤„ç†ï¼šç®€å•åˆ†æ®µ
            sentences = [s.strip() + '.' for s in request.transcript.split('.') if s.strip()]
            translations = []

            for i, sentence in enumerate(sentences[:30]):  # é™åˆ¶æœ€å¤š30å¥
                if sentence:
                    translations.append({
                        "english": sentence,
                        "chinese": f"[ç¿»è¯‘å¤±è´¥] å¥å­ {i+1}"
                    })

        logger.info(f"Generated {len(translations)} translation pairs")

        return YoutubeReportResponse(
            title=request.title,
            summary=summary,
            translations=[TranscriptLine(**t) for t in translations]
        )

    except Exception as e:
        logger.error(f"Error generating YouTube report: {e}")
        raise HTTPException(status_code=500, detail=str(e))
