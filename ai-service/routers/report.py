"""
æŠ¥å‘Šç”Ÿæˆè·¯ç”± - å¤šç´ æAIç»¼åˆæŠ¥å‘Š
"""
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
import json
import logging

from services.grok_client import GrokClient
from services.openai_client import OpenAIClient

router = APIRouter()
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–AIå®¢æˆ·ç«¯
grok_client = GrokClient()
openai_client = OpenAIClient()


class Resource(BaseModel):
    """èµ„æºæ¨¡å‹"""
    id: str
    title: str
    abstract: Optional[str] = None
    authors: Optional[Any] = None
    published_date: Optional[str] = None
    tags: Optional[Any] = None
    type: str


class ReportRequest(BaseModel):
    """æŠ¥å‘Šç”Ÿæˆè¯·æ±‚"""
    resources: List[Resource] = Field(..., min_items=2, max_items=10)
    template: str = Field(..., pattern="^(comparison|trend|learning-path|literature-review)$")
    model: str = Field(default="grok", pattern="^(grok|gpt-4)$")


class ReportSection(BaseModel):
    """æŠ¥å‘Šç« èŠ‚"""
    title: str
    content: str


class ReportResponse(BaseModel):
    """æŠ¥å‘Šå“åº”"""
    title: str
    summary: str
    sections: List[ReportSection]
    metadata: Optional[Dict[str, Any]] = None


def prepare_resources_info(resources: List[Resource]) -> str:
    """å‡†å¤‡èµ„æºä¿¡æ¯æ–‡æœ¬"""
    info_parts = []
    for i, resource in enumerate(resources, 1):
        # å¤„ç†authors
        authors_str = "N/A"
        if resource.authors:
            if isinstance(resource.authors, list):
                authors_str = ", ".join(resource.authors[:3])  # åªæ˜¾ç¤ºå‰3ä¸ªä½œè€…
            elif isinstance(resource.authors, str):
                authors_str = resource.authors

        # å¤„ç†tags
        tags_str = "N/A"
        if resource.tags:
            if isinstance(resource.tags, list):
                tags_str = ", ".join(resource.tags[:5])  # åªæ˜¾ç¤ºå‰5ä¸ªæ ‡ç­¾
            elif isinstance(resource.tags, str):
                tags_str = resource.tags

        # å¤„ç†abstract
        abstract = resource.abstract or "No abstract available"
        if len(abstract) > 500:
            abstract = abstract[:500] + "..."

        info = f"""
Resource {i}:
- ID: {resource.id}
- Title: {resource.title}
- Type: {resource.type}
- Date: {resource.published_date or 'N/A'}
- Authors: {authors_str}
- Tags: {tags_str}
- Abstract: {abstract}
"""
        info_parts.append(info)

    return "\n".join(info_parts)


# æŠ¥å‘Šæ¨¡æ¿Prompts
REPORT_PROMPTS = {
    "comparison": """You are a technical analyst. Analyze and compare the following {count} resources.

Resources:
{resources_info}

Generate a comprehensive comparison report with these sections:

1. **Executive Summary** (200-300 words)
   - Overview of all resources
   - Main themes and connections
   - Key takeaways

2. **Detailed Comparison**
   Create a comparison table in markdown format with these aspects:
   - Approach/Method
   - Key Innovation
   - Performance/Results
   - Limitations
   - Use Cases

3. **Key Insights** (5-7 bullet points)
   - Common patterns across resources
   - Key differences and trade-offs
   - Evolution and improvements
   - Complementary aspects

4. **Recommendations**
   - Which to choose for different scenarios
   - Learning order suggestions
   - Further reading

IMPORTANT: Output ONLY valid JSON in this exact format:
{{
  "title": "Comparison of [Topic]",
  "summary": "Executive summary text...",
  "sections": [
    {{"title": "Detailed Comparison", "content": "markdown table and text"}},
    {{"title": "Key Insights", "content": "markdown list"}},
    {{"title": "Recommendations", "content": "markdown text"}}
  ]
}}

JSON output:
""",

    "trend": """You are a technology trend analyst. Analyze the following {count} resources to identify trends.

Resources:
{resources_info}

Generate a trend analysis report with these sections:

1. **Overview** (150-200 words)
   - Time span covered
   - Main themes
   - Overall direction

2. **Technology Timeline**
   Create a chronological timeline in markdown format showing:
   - Year/Date
   - Key milestone
   - Innovation introduced
   - Impact level (High/Medium/Low)

3. **Key Breakthroughs** (4-6 items)
   For each breakthrough:
   - What changed
   - Why it matters
   - Follow-up work

4. **Trend Predictions**
   - Emerging patterns
   - Likely next developments (3-6 months)
   - Opportunities and challenges

IMPORTANT: Output ONLY valid JSON in this exact format:
{{
  "title": "Trend Analysis: [Topic]",
  "summary": "Overview text...",
  "sections": [
    {{"title": "Technology Timeline", "content": "markdown timeline"}},
    {{"title": "Key Breakthroughs", "content": "markdown list"}},
    {{"title": "Trend Predictions", "content": "markdown text"}}
  ]
}}

JSON output:
""",

    "learning-path": """You are a learning path designer. Create a structured learning plan from these {count} resources.

Resources:
{resources_info}

Generate a learning path report with these sections:

1. **Learning Objectives** (150 words)
   - What you'll learn
   - Target audience
   - Prerequisites

2. **Recommended Learning Sequence**
   For each resource (in order):
   - Resource title and type
   - Difficulty level (Beginner/Intermediate/Advanced)
   - Estimated time investment
   - Key concepts covered
   - Why this sequence matters

3. **Difficulty Analysis**
   - Concept progression
   - Knowledge dependencies
   - Potential challenges

4. **Practice Recommendations**
   - Hands-on projects
   - Additional resources
   - Learning tips

IMPORTANT: Output ONLY valid JSON in this exact format:
{{
  "title": "Learning Path: [Topic]",
  "summary": "Learning objectives text...",
  "sections": [
    {{"title": "Recommended Learning Sequence", "content": "markdown ordered list"}},
    {{"title": "Difficulty Analysis", "content": "markdown text"}},
    {{"title": "Practice Recommendations", "content": "markdown list"}}
  ]
}}

JSON output:
""",

    "literature-review": """You are an academic researcher. Write a literature review for these {count} resources.

Resources:
{resources_info}

Generate an academic literature review with these sections:

1. **Introduction and Background** (200-250 words)
   - Research context
   - Motivation and significance
   - Scope of review

2. **Methodology Evolution**
   Discuss how methods have evolved:
   - Early approaches
   - Key innovations
   - Current state-of-the-art

3. **Comparative Analysis**
   Create a detailed comparison of:
   - Research methods
   - Results and findings
   - Strengths and limitations

4. **Future Directions**
   - Open problems
   - Promising research directions
   - Potential applications

IMPORTANT: Output ONLY valid JSON in this exact format:
{{
  "title": "Literature Review: [Topic]",
  "summary": "Introduction text...",
  "sections": [
    {{"title": "Methodology Evolution", "content": "markdown text"}},
    {{"title": "Comparative Analysis", "content": "markdown text with tables"}},
    {{"title": "Future Directions", "content": "markdown list"}}
  ]
}}

JSON output:
"""
}


def parse_json_response(response_text: str) -> Dict[str, Any]:
    """è§£æAIå“åº”ä¸­çš„JSON"""
    try:
        # å°è¯•ç›´æ¥è§£æ
        return json.loads(response_text)
    except json.JSONDecodeError:
        # å°è¯•æå–JSONéƒ¨åˆ†
        response_text = response_text.strip()

        # ç§»é™¤markdownä»£ç å—
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()

        # æŸ¥æ‰¾JSONå¯¹è±¡
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}')

        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            json_str = response_text[start_idx:end_idx + 1]
            try:
                return json.loads(json_str)
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse JSON: {e}\nContent: {json_str[:200]}")
                raise

        raise ValueError("No valid JSON found in response")


@router.post("/api/v1/ai/generate-report", response_model=ReportResponse)
async def generate_report(request: ReportRequest):
    """
    ç”Ÿæˆå¤šç´ æç»¼åˆæŠ¥å‘Š

    Args:
        request: åŒ…å«èµ„æºåˆ—è¡¨ã€æ¨¡æ¿å’Œæ¨¡å‹çš„è¯·æ±‚

    Returns:
        ReportResponse: ç»“æ„åŒ–çš„æŠ¥å‘Šå†…å®¹
    """
    try:
        logger.info(f"Generating {request.template} report for {len(request.resources)} resources using {request.model}")

        # 1. å‡†å¤‡èµ„æºä¿¡æ¯
        resources_info = prepare_resources_info(request.resources)

        # 2. é€‰æ‹©promptæ¨¡æ¿
        prompt_template = REPORT_PROMPTS.get(request.template)
        if not prompt_template:
            raise HTTPException(status_code=400, detail=f"Invalid template: {request.template}")

        # 3. æ„å»ºå®Œæ•´prompt
        prompt = prompt_template.format(
            count=len(request.resources),
            resources_info=resources_info
        )

        # 4. è°ƒç”¨AIç”Ÿæˆ
        if request.model == "gpt-4":
            logger.info("Using OpenAI GPT-4")
            response = await openai_client.chat(
                messages=[{
                    "role": "system",
                    "content": "You are a helpful AI assistant that generates structured reports. Always output valid JSON."
                }, {
                    "role": "user",
                    "content": prompt
                }],
                model="gpt-4",
                temperature=0.7,
                max_tokens=3000
            )
        else:
            logger.info("Using Grok")
            response = await grok_client.chat(
                messages=[{
                    "role": "system",
                    "content": "You are a helpful AI assistant that generates structured reports. Always output valid JSON."
                }, {
                    "role": "user",
                    "content": prompt
                }],
                temperature=0.7,
                max_tokens=3000
            )

        # 5. è§£æå“åº”
        report_data = parse_json_response(response)

        # 6. éªŒè¯å¿…éœ€å­—æ®µ
        if "title" not in report_data or "summary" not in report_data or "sections" not in report_data:
            raise ValueError("Response missing required fields: title, summary, or sections")

        # 7. æ„å»ºå“åº”
        result = ReportResponse(
            title=report_data["title"],
            summary=report_data["summary"],
            sections=[
                ReportSection(title=s["title"], content=s["content"])
                for s in report_data["sections"]
            ],
            metadata={
                "model": request.model,
                "template": request.template,
                "resourceCount": len(request.resources),
            }
        )

        logger.info(f"Successfully generated report: {result.title}")
        return result

    except json.JSONDecodeError as e:
        logger.error(f"JSON parsing error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to parse AI response as JSON: {str(e)}"
        )
    except Exception as e:
        logger.error(f"Report generation error: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Failed to generate report: {str(e)}"
        )


@router.get("/api/v1/ai/report-templates")
async def get_report_templates():
    """è·å–å¯ç”¨çš„æŠ¥å‘Šæ¨¡æ¿åˆ—è¡¨"""
    return {
        "templates": [
            {
                "id": "comparison",
                "name": "å¯¹æ¯”åˆ†æ",
                "description": "å¤šç»´åº¦å¯¹æ¯”å„ç´ æçš„ç‰¹ç‚¹ã€ä¼˜åŠ£åŠ¿å’Œé€‚ç”¨åœºæ™¯",
                "icon": "ğŸ“Š",
                "minItems": 2,
                "maxItems": 5,
                "estimatedTime": "60ç§’",
                "model": "gpt-4",
            },
            {
                "id": "trend",
                "name": "è¶‹åŠ¿æŠ¥å‘Š",
                "description": "åˆ†ææŠ€æœ¯æ¼”è¿›è½¨è¿¹å’Œæœªæ¥å‘å±•æ–¹å‘",
                "icon": "ğŸ“ˆ",
                "minItems": 3,
                "maxItems": 10,
                "estimatedTime": "45ç§’",
                "model": "grok",
            },
            {
                "id": "learning-path",
                "name": "å­¦ä¹ è·¯å¾„",
                "description": "ç”Ÿæˆç”±æµ…å…¥æ·±çš„å­¦ä¹ è®¡åˆ’å’Œå®è·µå»ºè®®",
                "icon": "ğŸ—ºï¸",
                "minItems": 3,
                "maxItems": 8,
                "estimatedTime": "50ç§’",
                "model": "grok",
            },
            {
                "id": "literature-review",
                "name": "æ–‡çŒ®ç»¼è¿°",
                "description": "å­¦æœ¯é£æ ¼çš„æ–‡çŒ®ç»¼è¿°æŠ¥å‘Š",
                "icon": "ğŸ“",
                "minItems": 5,
                "maxItems": 10,
                "estimatedTime": "90ç§’",
                "model": "gpt-4",
            },
        ]
    }
