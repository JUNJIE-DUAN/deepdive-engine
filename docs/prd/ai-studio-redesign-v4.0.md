# AI Studio 全新设计 PRD v4.0

## NotebookLM 对标重设计方案

**版本**: 4.0 (Updated)
**日期**: 2025-11-29
**状态**: 待评审
**核心目标**: 打造真正好用的 AI 研究助手，对标 Google NotebookLM 2024年12月最新设计

**参考资料**:

- [NotebookLM gets a new look - Google Blog](https://blog.google/technology/google-labs/notebooklm-new-features-december-2024/)
- [Google Updates NotebookLM - Maginative](https://www.maginative.com/article/google-updates-notebooklm-with-new-interface-interactive-audio-features-and-premium-tier/)
- [NotebookLM redesign - 9to5Google](https://9to5google.com/2024/12/13/notebooklm-redesign-plus-tier/)

---

## 1. 问题诊断：当前设计的致命缺陷

### 1.1 截图分析

从当前截图看，存在以下严重问题：

```
┌─────────────────────────────────────────────────────────────────────┐
│ 当前设计问题                                                         │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ❌ 问题1: 搜索框过于突出，但搜索不是核心动作                        │
│     - 用户进入页面首先看到的是搜索，而不是研究任务                   │
│     - 搜索结果(30条)展示在主要位置，但用户还没开始研究               │
│                                                                     │
│  ❌ 问题2: "研究计划"显示100%但内容空洞                              │
│     - 3个步骤都显示完成，但实际没有深度分析                          │
│     - "分析已选资源 2个资源" - 这不是有价值的洞察                    │
│                                                                     │
│  ❌ 问题3: 右侧"洞察画廊"完全没有内容                                │
│     - 只显示一个研究结果，没有任何可操作的洞察                       │
│     - 缺少 NotebookLM 的"笔记本"概念                                │
│                                                                     │
│  ❌ 问题4: 布局混乱，信息层级不清                                    │
│     - 左侧有搜索范围切换、搜索框、研究计划、搜索结果                 │
│     - 用户不知道该从哪里开始                                         │
│                                                                     │
│  ❌ 问题5: 缺少"Notebook"核心概念                                   │
│     - NotebookLM 的精髓是：先建笔记本 → 上传资料 → AI 分析           │
│     - 当前设计直接跳过了"建立研究项目"这个关键步骤                   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 1.2 NotebookLM 为什么好用？

```
NotebookLM 核心设计理念:

1. 📓 Notebook First (笔记本优先)
   - 每个研究任务是一个独立的 Notebook
   - 用户先创建笔记本，定义研究主题
   - 所有后续操作都在这个笔记本内进行

2. 📚 Sources as Foundation (资料是基础)
   - 上传/添加资料是第一步
   - AI 所有分析都基于这些资料
   - 用户清楚知道 AI 在分析什么

3. 💬 Chat with Your Sources (与资料对话)
   - 不是通用 AI 聊天
   - 是针对你的资料进行问答
   - 每个回答都有明确引用

4. 📝 Notes as Output (笔记是产出)
   - 对话中的重要内容可以保存为笔记
   - 笔记可以编辑、组织、导出
   - 笔记是用户的知识资产

5. 🎙️ Audio Overview (音频概述)
   - 把研究内容变成播客
   - 这是独特的"惊喜时刻"
```

---

## 2. 全新设计方案

### 2.1 核心理念转变

| 维度     | 旧设计           | 新设计                    |
| -------- | ---------------- | ------------------------- |
| 入口     | 搜索框           | 研究项目列表              |
| 核心概念 | 搜索 → 分析      | 项目 → 资料 → 对话 → 笔记 |
| 信息组织 | 搜索结果堆砌     | 项目化管理                |
| 产出形式 | 洞察报告         | 笔记 + 报告 + 播客        |
| 用户心智 | "这是个搜索工具" | "这是我的研究助手"        |

### 2.2 新的页面架构

```
┌─────────────────────────────────────────────────────────────────────┐
│                    AI Studio 全新架构                                │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  页面1: 研究项目列表 (/studio)                                       │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━    │
│  显示所有研究项目（类似 NotebookLM 首页）                            │
│  - 最近项目                                                          │
│  - 创建新项目                                                        │
│  - 项目搜索                                                          │
│                                                                     │
│                           ↓ 进入项目                                 │
│                                                                     │
│  页面2: 研究项目详情 (/studio/[projectId])                           │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━    │
│  三栏布局:                                                           │
│  ┌─────────────┬──────────────────────────┬─────────────────┐       │
│  │   资料库     │      AI 对话区           │    笔记/产出    │       │
│  │   (Sources)  │      (Chat)              │    (Notes)      │       │
│  │             │                          │                 │       │
│  │  已添加资料  │  与你的资料对话          │  保存的笔记     │       │
│  │  添加更多    │  每个回答有引用          │  生成的报告     │       │
│  │             │                          │  音频概述       │       │
│  └─────────────┴──────────────────────────┴─────────────────┘       │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 3. 页面详细设计

### 3.1 页面1: 研究项目列表 (/studio)

```
┌─────────────────────────────────────────────────────────────────────┐
│  [Logo] DeepDive                                              [👤]   │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│                                                                     │
│                        🔬 AI 研究工作台                              │
│                                                                     │
│             上传资料，让 AI 帮你深度分析和研究                       │
│                                                                     │
│                  ┌────────────────────────────┐                     │
│                  │  + 创建新研究项目           │                     │
│                  └────────────────────────────┘                     │
│                                                                     │
│  ──────────────────────────────────────────────────────────────     │
│                                                                     │
│  最近项目                                                    查看全部│
│                                                                     │
│  ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐       │
│  │ 📓              │ │ 📓              │ │ 📓              │       │
│  │ LLM推理优化研究  │ │ MoE架构对比分析  │ │ AI Agent技术追踪│       │
│  │                 │ │                 │ │                 │       │
│  │ 5 个资料源      │ │ 8 个资料源      │ │ 12 个资料源     │       │
│  │ 3 条笔记        │ │ 7 条笔记        │ │ 2 条笔记        │       │
│  │                 │ │                 │ │                 │       │
│  │ 今天 10:30      │ │ 昨天            │ │ 3天前           │       │
│  └─────────────────┘ └─────────────────┘ └─────────────────┘       │
│                                                                     │
│  ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐       │
│  │ 📓              │ │ 📓              │ │ 📓              │       │
│  │ Rust vs Go对比   │ │ 2024 AI趋势     │ │ RAG最佳实践     │       │
│  │ ...             │ │ ...             │ │ ...             │       │
│  └─────────────────┘ └─────────────────┘ └─────────────────┘       │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**交互设计**:

- 点击 "+ 创建新研究项目" → 弹出创建对话框
- 点击项目卡片 → 进入项目详情页
- 右键项目卡片 → 重命名/删除/复制

**创建项目对话框**:

```
┌─────────────────────────────────────────────────────────────────────┐
│  创建研究项目                                               [✕]     │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  项目名称                                                            │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ LLM推理优化技术研究                                          │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│  项目描述（可选）                                                    │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ 研究vLLM、TensorRT-LLM等推理框架的技术路线和性能对比         │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│  快速开始                                                            │
│  ○ 空白项目 - 稍后添加资料                                          │
│  ● 从搜索开始 - 搜索相关资料并自动添加                               │
│  ○ 上传文件 - 上传PDF、文档等                                        │
│                                                                     │
│  [如果选择"从搜索开始"]                                              │
│  搜索关键词                                                          │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ vLLM TensorRT-LLM inference optimization                     │   │
│  └─────────────────────────────────────────────────────────────┘   │
│  搜索范围: ☑ arXiv论文  ☑ GitHub项目  ☑ 科技资讯                    │
│                                                                     │
│                                         [取消]  [创建并开始研究]     │
└─────────────────────────────────────────────────────────────────────┘
```

---

### 3.2 页面2: 研究项目详情 (/studio/[projectId])

**完全对标 NotebookLM 2024年12月最新设计**

> **设计理念**: "左侧是输入（知识来源），中间是理解和探索，右侧是输出（生成产出）"
>
> 三栏布局"流动自适应你的需求"，Sources 栏可收缩为导航栏或展开查看文档

#### 3.2.0 整体布局架构 (用户体验优化版)

> **产品经理视角**: 好的设计是"渐进式披露"，用户在不同阶段只看到需要的东西。
>
> NotebookLM 的核心体验是：**简单 → 深入 → 产出**，而不是一开始就展示所有功能。

**设计原则**:

1. **聚焦核心任务** - Chat 是主角，Sources 和 Studio 是配角
2. **减少认知负担** - 操作按钮悬浮显示，不常驻
3. **清晰的视觉层级** - 中间对话区最大，两侧辅助
4. **统一的输入入口** - 只有一个输入框，智能识别意图

---

### 方案 A：极简聚焦式 (推荐)

**核心思路**: 把搜索、对话、研究统一到一个输入框，根据用户输入智能判断意图。

#### 完整布局（含全局导航）

```
┌────┬────────────────────────────────────────────────────────────────────────────────────┐
│    │  LLM推理优化研究                                       [分享]  [导出]    [设置]    │
│ D  ├───────────┬─────────────────────────────────────────────────────────┬──────────────┤
│ e  │           │                                                         │              │
│ e  │  📚       │                                                         │    🎨       │
│ p  │  Sources  │                      💬 对话                            │    Studio   │
│ D  │           │                                                         │              │
│ i  │  ─────    │         ┌───────────────────────────────────┐          │    ─────    │
│ v  │           │         │                                   │          │              │
│ e  │  5 个资料  │         │    👋 你好！我已准备好帮你研究     │          │    📝 笔记  │
│    │           │         │                                   │          │    3 条     │
│ ── │  📄 vLLM  │         │    基于你添加的 5 个资料，         │          │              │
│    │  📄 TRT   │         │    你可以问我任何问题。            │          │    ─────    │
│ 🔍 │  💻 Repo  │         │                                   │          │              │
│ 📚 │  📰 博客  │         │    💡 试试这些:                    │          │    一键生成  │
│ 🔬 │  📄 llama │         │                                   │          │              │
│ 📊 │           │         │    "总结核心观点"                  │          │    📋 指南  │
│ ⚙️ │  ─────    │         │    "对比技术方案"                  │          │    📄 简报  │
│    │           │         │    "分析发展趋势"                  │          │    ❓ FAQ   │
│ ── │  [+添加]  │         │                                   │          │    🎙️ 播客  │
│    │           │         └───────────────────────────────────┘          │              │
│ 👤 │           │                                                         │              │
│    │           │  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  │              │
│    │           │                                                         │              │
│    │           │  ┌─────────────────────────────────────────────────┐   │              │
│    │           │  │                                                 │   │              │
│    │           │  │  输入问题，或搜索添加更多资料...                 │   │              │
│    │           │  │                                         [发送]  │   │              │
│    │           │  │                                                 │   │              │
│    │           │  │  [🌐 联网]  [⚡快速] [🔬深度]                   │   │              │
│    │           │  └─────────────────────────────────────────────────┘   │              │
│    │           │                                                         │              │
└────┴───────────┴─────────────────────────────────────────────────────────┴──────────────┘
```

#### 全局左侧导航栏 (始终显示)

**沿用现有设计**: 使用现有的全局侧边栏组件 `frontend/components/layout/Sidebar.tsx`

```
折叠状态 (默认，宽度 64px)          展开状态 (宽度 208px)
┌────┐                              ┌──────────────────┐
│    │                              │                  │
│ DD │  ← DeepDive Logo             │  [Logo] DeepDive │
│    │                              │         Engine   │
├────┤                              ├──────────────────┤
│    │                              │                  │
│ 🔍 │  ← Explore                   │  🔍 Explore      │
│ 🏛️ │  ← AI Picks                  │  🏛️ AI Picks     │
│ 📊 │  ← AI Office                 │  📊 AI Office [n]│ ← 显示资源数
│ 📈 │  ← AI Studio (当前)          │  📈 AI Studio    │ ← 当前高亮
│ 👥 │  ← AI Group                  │  👥 AI Group     │
│ ⚙️ │  ← Settings (管理员可见)      │  ⚙️ Settings     │
│    │                              │                  │
├────┤                              ├──────────────────┤
│    │                              │                  │
│ 🔔 │  ← Notifications             │  🔔 Notifications│
│ 👤 │  ← User Profile              │  👤 User Profile │
│ 🧪 │  ← Labs                      │  🧪 Labs         │
│ 💬 │  ← Feedback                  │  💬 Feedback     │
│    │                              │                  │
└────┘                              └──────────────────┘
```

**现有导航栏特性**:

| 菜单项        | 路由                         | 说明                          |
| ------------- | ---------------------------- | ----------------------------- |
| Explore       | `/`                          | 首页探索                      |
| AI Picks      | `/library`                   | AI 推荐资料库                 |
| AI Office     | `/ai-office`                 | AI 办公工作区，显示资源数徽章 |
| AI Studio     | `/studio`                    | 研究工作台（本PRD设计页面）   |
| AI Group      | `/ai-group`                  | AI 群组协作                   |
| Settings      | `/data-collection/dashboard` | 系统设置（仅管理员可见）      |
| Notifications | `/notifications`             | 通知中心                      |
| User Profile  | -                            | 用户信息/登录                 |
| Labs          | `/labs`                      | 实验室功能                    |
| Feedback      | `/feedback`                  | 反馈入口                      |

**交互行为**:

- **默认折叠** - localStorage 持久化状态，默认宽度 64px
- **点击切换** - 通过右侧居中按钮展开/收起
- **当前页高亮** - 使用不同背景色高亮当前页面
- **AI Office 徽章** - 显示当前资源数量

**关键设计点**:

1. **统一输入框** - 底部只有一个输入框
   - 输入问题 → 基于资料回答
   - 输入搜索词 + 点击 [🌐联网] → 搜索并添加资料
   - 输入研究问题 + 点击 [🔬深度] → 启动深度研究

2. **左侧 Sources 极简化**
   - 只显示资料数量和图标
   - 点击展开详情
   - 悬浮显示操作按钮

3. **右侧 Studio 极简化**
   - 笔记数量 + 一键生成按钮
   - 点击展开详情

4. **中间对话区主导**
   - 占据最大空间
   - 欢迎语 + 智能建议
   - 对话历史

---

### 方案 B：标签切换式

**核心思路**: 用标签页切换不同功能区，一次只聚焦一件事。

```
┌─────────────────────────────────────────────────────────────────────────────────────┐
│  [←] LLM推理优化研究                                    [分享]  [导出]    [设置]    │
├─────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                     │
│  ┌─────────────┬─────────────┬─────────────┬─────────────┐                         │
│  │  💬 对话    │  📚 资料    │  🔍 搜索    │  🎨 产出    │                         │
│  │  (当前)     │  (5)        │             │  (3)        │                         │
│  └─────────────┴─────────────┴─────────────┴─────────────┘                         │
│                                                                                     │
│  ┌─────────────────────────────────────────────────────────────────────────────┐   │
│  │                                                                             │   │
│  │                         [对话区内容]                                        │   │
│  │                                                                             │   │
│  │     👋 你好！基于你添加的 5 个资料，你可以问我任何问题。                     │   │
│  │                                                                             │   │
│  │     💡 试试这些:                                                            │   │
│  │        • "总结这些资料的核心观点"                                           │   │
│  │        • "对比 vLLM 和 TensorRT-LLM"                                       │   │
│  │        • "分析 LLM 推理优化的发展趋势"                                      │   │
│  │                                                                             │   │
│  │                                                                             │   │
│  │                                                                             │   │
│  │                                                                             │   │
│  │                                                                             │   │
│  │  ───────────────────────────────────────────────────────────────────────   │   │
│  │                                                                             │   │
│  │  ┌─────────────────────────────────────────────────────────────────────┐   │   │
│  │  │  输入问题...                                                 [发送] │   │   │
│  │  └─────────────────────────────────────────────────────────────────────┘   │   │
│  │                                                                             │   │
│  └─────────────────────────────────────────────────────────────────────────────┘   │
│                                                                                     │
└─────────────────────────────────────────────────────────────────────────────────────┘
```

点击 [🔍 搜索] 标签：

```
│  ┌─────────────┬─────────────┬─────────────┬─────────────┐                         │
│  │  💬 对话    │  📚 资料    │  🔍 搜索    │  🎨 产出    │                         │
│  │             │  (5)        │  (当前)     │  (3)        │                         │
│  └─────────────┴─────────────┴─────────────┴─────────────┘                         │
│                                                                                     │
│  ┌─────────────────────────────────────────────────────────────────────────────┐   │
│  │                                                                             │   │
│  │  ┌───────────────────────────────────────────────────────────────────────┐ │   │
│  │  │  🔍 搜索资料...                                               [搜索] │ │   │
│  │  └───────────────────────────────────────────────────────────────────────┘ │   │
│  │                                                                             │   │
│  │  搜索模式:  [⚡ 快速搜索]  [🔬 深度研究]       来源: [☑arXiv] [☑GitHub]    │   │
│  │                                                                             │   │
│  │  ───────────────────────────────────────────────────────────────────────   │   │
│  │                                                                             │   │
│  │  最近搜索:                                                                  │   │
│  │  • vLLM inference optimization                                              │   │
│  │  • TensorRT-LLM performance                                                 │   │
│  │                                                                             │   │
│  │  热门推荐:                                                                  │   │
│  │  • LLM 推理优化最新论文                                                     │   │
│  │  • Speculative Decoding 技术                                                │   │
│  │                                                                             │   │
│  └─────────────────────────────────────────────────────────────────────────────┘   │
```

---

### 方案对比与推荐

| 维度         | 方案 A (极简聚焦)   | 方案 B (标签切换) |
| ------------ | ------------------- | ----------------- |
| **认知负担** | ⭐⭐⭐⭐⭐ 最低     | ⭐⭐⭐⭐ 较低     |
| **操作效率** | ⭐⭐⭐⭐ 较高       | ⭐⭐⭐⭐⭐ 最高   |
| **信息密度** | ⭐⭐⭐ 适中         | ⭐⭐⭐⭐ 较高     |
| **学习成本** | ⭐⭐⭐⭐⭐ 最低     | ⭐⭐⭐⭐ 较低     |
| **类似产品** | NotebookLM, ChatGPT | Notion, Linear    |

**推荐方案 A**：更接近 NotebookLM 的设计理念，对话为中心，渐进式披露其他功能。

---

### 方案 A 详细设计

#### 输入框智能识别

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                                                                             │
│  ┌───────────────────────────────────────────────────────────────────────┐ │
│  │  输入问题，或搜索添加更多资料...                               [发送] │ │
│  └───────────────────────────────────────────────────────────────────────┘ │
│                                                                             │
│  模式:  ○ 💬 对话 (默认)   ○ 🔍 搜索资料   ○ 🔬 深度研究                   │
│                                                                             │
│  [🌐 联网搜索]  来源: arXiv · GitHub · 资讯                                 │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**模式说明**:

| 模式            | 触发方式                | 行为                         |
| --------------- | ----------------------- | ---------------------------- |
| 💬 **对话**     | 默认 / 输入问句         | 基于已有资料回答问题         |
| 🔍 **搜索资料** | 点击切换 / 输入关键词   | 搜索并展示结果，可添加到项目 |
| 🔬 **深度研究** | 点击切换 / 输入研究问题 | AI 自动搜索、分析、生成报告  |

**智能识别示例**:

- "总结核心观点" → 💬 对话模式
- "vLLM" → 🔍 搜索模式 (识别为关键词)
- "分析 vLLM 和 TensorRT 的技术差异" → 🔬 深度研究模式 (识别为研究问题)

#### 3.2.1 左栏: Sources Panel (资料面板)

> **NotebookLM 设计**: Sources 面板管理项目的所有信息来源，可收缩为导航栏或展开查看文档

**核心功能**:

1. **添加资料** (顶部固定按钮)
   - 搜索添加 (arXiv/GitHub/News/Web)
   - URL 添加 (粘贴链接自动解析)
   - 文件上传 (PDF/DOCX/TXT/MD)
   - 粘贴文本 (直接粘贴内容)

2. **资料列表** (带多选)
   - ☑ 复选框选择资料用于对话
   - 资料图标表示类型 (📄论文/💻代码/📰资讯)
   - 显示分析状态 (✓已分析/🔄分析中/⚠️失败)
   - **每个资料项都有操作按钮**: [👁️ 查看] [⬇️ 下载]

3. **资料操作** (每个资料项右侧)
   | 操作 | 图标 | 说明 |
   |------|------|------|
   | 展开查看 | 👁️ | 在右侧面板展开查看完整内容 |
   | 下载原文 | ⬇️ | 下载 PDF/源文件到本地 |
   | 在新标签打开 | 🔗 | 打开原始链接 |
   | 移除 | 🗑️ | 从项目中移除 |

4. **资料状态**
   | 状态 | 图标 | 说明 |
   |------|------|------|
   | 待分析 | ⏳ | 刚添加，等待处理 |
   | 分析中 | 🔄 | AI 正在解析内容 |
   | 已分析 | ✓ | 可用于对话和生成 |
   | 失败 | ⚠️ | 点击重试 |

5. **批量操作** (底部)
   - [选中 N 个资料] 显示当前选中数量
   - [全选] 选择所有资料
   - [仅用选中] 对话时只使用选中的资料
   - [批量下载] 下载选中的所有资料

6. **面板收缩** (NotebookLM 特色)
   - 点击面板边缘可收缩为窄栏
   - 收缩后只显示资料图标
   - 再次点击展开

**添加资料对话框** (增强版):

```
┌─────────────────────────────────────────────────────────────────────┐
│  添加研究资料                                                [✕]     │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ┌─────────────┬─────────────┬─────────────┬─────────────┐         │
│  │   🔍 搜索   │   🔗 链接   │   📄 上传   │   📋 粘贴   │         │
│  │   (选中)    │             │             │             │         │
│  └─────────────┴─────────────┴─────────────┴─────────────┘         │
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ 🔍 vLLM inference optimization                               │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│  搜索模式                                                            │
│  ┌────────────────────────┐  ┌────────────────────────┐            │
│  │ ⚡ 快速搜索 (选中)      │  │ 🔬 深度搜索            │            │
│  │ 实时返回，适合浏览      │  │ 全面抓取，适合研究      │            │
│  └────────────────────────┘  └────────────────────────┘            │
│                                                                     │
│  搜索来源                                                            │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐      │
│  │☑ arXiv │ │☑ GitHub│ │☑ 资讯  │ │☐ 博客  │ │☐ 本地  │      │
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘ └─────────┘      │
│                                                                     │
│  搜索结果 (12)                                              [刷新]  │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━   │
│                                                                     │
│  ☑ 📄 Efficient Memory Management for LLMs with PagedAttention     │
│       arXiv · 2023-09 · 引用 1.2k · ⭐ 高影响力                      │
│       [👁️ 查看] [⬇️ 下载] [💾 存入数据库]                           │
│                                                                     │
│  ☑ 💻 vllm-project/vllm                                             │
│       GitHub · ⭐28.5k · 最近更新 2h · Python                        │
│       [👁️ 查看] [⬇️ 下载] [💾 存入数据库]                           │
│                                                                     │
│  ☐ 📄 TensorRT-LLM: Efficient LLM Inference Framework              │
│       arXiv · 2024-01 · 引用 856                                    │
│       [👁️ 查看] [⬇️ 下载] [💾 存入数据库]                           │
│                                                                     │
│  ☐ 📰 LLM Inference Optimization: A Comprehensive Survey           │
│       HuggingFace Blog · 2024-06                                    │
│       [👁️ 查看] [⬇️ 下载] [💾 存入数据库]                           │
│                                                                     │
│  [加载更多...]                                                       │
│                                                                     │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━   │
│                                                                     │
│  选中 2 项:  [💾 批量存入数据库]  [⬇️ 批量下载]                      │
│                                                                     │
│                    [取消]     [添加到当前项目 (2)]                    │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**搜索模式说明**:

| 模式            | 图标 | 说明                                | 适用场景               |
| --------------- | ---- | ----------------------------------- | ---------------------- |
| ⚡ **快速搜索** | ⚡   | 仅获取标题、摘要等元数据，实时返回  | 快速浏览，找到相关资料 |
| 🔬 **深度搜索** | 🔬   | 抓取完整内容、PDF全文、代码仓库详情 | 深度研究，需要完整内容 |

**搜索结果操作**:

| 操作              | 说明                                                       |
| ----------------- | ---------------------------------------------------------- |
| 👁️ **查看**       | 展开查看完整内容（深度搜索模式下可查看全文）               |
| ⬇️ **下载**       | 下载 PDF/源文件到本地                                      |
| 💾 **存入数据库** | 将资料永久保存到 DeepDive 数据库，后续可在"本地"搜索中找到 |
| ☑ **选中**       | 添加到当前研究项目                                         |

**批量操作**:

- [💾 批量存入数据库] - 将选中的资料全部保存到数据库
- [⬇️ 批量下载] - 批量下载选中的资料

**资料详情预览** (点击 👁️ 查看时弹出 - 全屏模态框):

```
┌─────────────────────────────────────────────────────────────────────────────┐
│  📄 Efficient Memory Management for LLMs with PagedAttention    [✕ 关闭]    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─ 元信息 ────────────────────────────────────────────────────────────┐   │
│  │  来源: arXiv:2309.06180                                              │   │
│  │  作者: Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, et al.               │   │
│  │  机构: UC Berkeley, Stanford                                         │   │
│  │  日期: 2023-09-12                                                    │   │
│  │  引用: 1,234  |  下载: 15.6k  |  ⭐ 高影响力                          │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│  ┌─ 操作栏 ────────────────────────────────────────────────────────────┐   │
│  │  [⬇️ 下载 PDF]  [🔗 打开原文]  [💾 存入数据库]  [📋 复制链接]         │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━   │
│                                                                             │
│  ┌─ 📝 AI 摘要 ────────────────────────────────────────────────────────┐   │
│  │                                                                      │   │
│  │  本文提出 PagedAttention，一种受操作系统虚拟内存和分页机制启发的      │   │
│  │  注意力算法。通过将 KV cache 分页存储到非连续的内存空间中，解决了     │   │
│  │  LLM 推理服务中的内存碎片问题，实现了接近零的内存浪费。               │   │
│  │                                                                      │   │
│  │  基于 PagedAttention，作者构建了 vLLM 系统，在各种模型和工作负载      │   │
│  │  下实现了 2-4 倍的吞吐量提升，相比 HuggingFace Transformers 提升     │   │
│  │  高达 24 倍。                                                         │   │
│  │                                                                      │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│  ┌─ 🔑 关键要点 ───────────────────────────────────────────────────────┐   │
│  │                                                                      │   │
│  │  • PagedAttention 将 KV cache 分为固定大小的块 (blocks)              │   │
│  │  • 每个块存储固定数量 token 的 key 和 value 向量                     │   │
│  │  • 支持非连续内存存储，大幅减少内存碎片                               │   │
│  │  • 支持灵活的内存共享，优化 parallel sampling 和 beam search         │   │
│  │  • vLLM 系统基于此技术，成为主流 LLM 推理框架                        │   │
│  │  • 在 A100 GPU 上实现 24x 吞吐提升                                   │   │
│  │                                                                      │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│  ┌─ 📄 原文内容 ───────────────────────────────────────────────────────┐   │
│  │  [展开/收起]                                          [全屏阅读]     │   │
│  ├──────────────────────────────────────────────────────────────────────┤   │
│  │                                                                      │   │
│  │  Abstract                                                            │   │
│  │  ──────────────────────────────────────────────────────────────     │   │
│  │  High throughput serving of large language models (LLMs) requires    │   │
│  │  batching sufficiently many requests at a time. However, existing    │   │
│  │  systems struggle to do so because the key-value cache (KV cache)    │   │
│  │  memory for each request is huge and grows and shrinks dynamically.  │   │
│  │  When managed inefficiently, this memory can be significantly        │   │
│  │  wasted by fragmentation and redundant duplication, limiting the     │   │
│  │  batch size...                                                       │   │
│  │                                                                      │   │
│  │  1. Introduction                                                     │   │
│  │  ──────────────────────────────────────────────────────────────     │   │
│  │  The emergence of large language models (LLMs) like GPT and PaLM     │   │
│  │  has enabled new applications such as programming assistants and     │   │
│  │  universal chatbots...                                               │   │
│  │                                                                      │   │
│  │  [继续阅读...]                                                       │   │
│  │                                                                      │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━   │
│                                                                             │
│  [添加到当前项目]  [💾 存入数据库]  [⬇️ 下载 PDF]  [🗑️ 移除]              │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**资料列表项** (Sources Panel 中每个资料的展示):

```
┌─────────────────────────────────────────────────────────────────────┐
│  ☑ 📄 Efficient Memory Management for LLMs with PagedAttention     │
│       arXiv · 2023-09 · 引用 1.2k · ✓ 已分析                        │
│                                                                     │
│       [👁️ 查看]  [⬇️ 下载]  [🔗 原文]  [···]                        │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘

点击 [···] 展开更多操作:
┌─────────────────────┐
│  📋 复制链接        │
│  💾 存入数据库      │
│  🗑️ 从项目移除      │
└─────────────────────┘
```

#### 3.2.2 中栏: Chat Panel (对话面板)

> **NotebookLM 设计**: Chat 面板让你通过对话式 AI 界面讨论你的资料，带有引用标注

**界面布局**:

```
┌─────────────────────────────────────────────────────────────────────┐
│                          💬 Chat                                     │
│                                                                     │
│              与你的资料对话 · 基于 5 个资料源                         │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                                                             │   │
│  │  💡 开始探索你的资料                                         │   │
│  │                                                             │   │
│  │  ┌─────────────────────────────────────────────────────┐   │   │
│  │  │  "总结这些资料的核心观点"                             │   │   │
│  │  └─────────────────────────────────────────────────────┘   │   │
│  │  ┌─────────────────────────────────────────────────────┐   │   │
│  │  │  "对比 vLLM 和 TensorRT-LLM 的技术路线"             │   │   │
│  │  └─────────────────────────────────────────────────────┘   │   │
│  │  ┌─────────────────────────────────────────────────────┐   │   │
│  │  │  "分析 LLM 推理优化的发展趋势"                       │   │   │
│  │  └─────────────────────────────────────────────────────┘   │   │
│  │                                                             │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━   │
│                                                                     │
│  [对话历史 - 滚动区域]                                               │
│                                                                     │
│  ┌─ 你 ──────────────────────────────────────────────────────────┐ │
│  │ 对比 vLLM 和 TensorRT-LLM 的性能差异                          │ │
│  └───────────────────────────────────────────────────────────────┘ │
│                                                                     │
│  ┌─ AI ──────────────────────────────────────────────────────────┐ │
│  │                                                               │ │
│  │ ## vLLM vs TensorRT-LLM 性能对比                              │ │
│  │                                                               │ │
│  │ 根据你提供的资料，以下是详细对比：                              │ │
│  │                                                               │ │
│  │ ### 核心技术路线                                               │ │
│  │                                                               │ │
│  │ **vLLM** [1]                                                  │ │
│  │ - PagedAttention 分页内存管理                                  │ │
│  │ - 显存利用率高达 95%                                          │ │
│  │                                                               │ │
│  │ **TensorRT-LLM** [2]                                          │ │
│  │ - 基于 TensorRT 深度优化                                       │ │
│  │ - 硬件级 CUDA 加速                                            │ │
│  │                                                               │ │
│  │ | 指标 | vLLM | TensorRT | 来源 |                             │ │
│  │ |------|------|----------|------|                             │ │
│  │ | 吞吐 | 2.3k | 2.9k     | [3]  |                             │ │
│  │ | 延迟 | 45ms | 32ms     | [3]  |                             │ │
│  │                                                               │ │
│  │ ─────────────────────────────────────────────────────────────│ │
│  │ 引用: [1] vLLM论文 [2] TensorRT文档 [3] HF博客                │ │
│  │                                                               │ │
│  │                    [💾 保存到笔记] [📋 复制] [👍] [👎]         │ │
│  └───────────────────────────────────────────────────────────────┘ │
│                                                                     │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━   │
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ 输入问题...                                          [发送] │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**核心特点**:

1. **智能建议问题** (初始状态)
   - 根据资料内容自动生成建议问题
   - 点击即可发送
   - 帮助用户快速开始

2. **基于资料的回答**
   - 顶部显示 "基于 N 个资料源"
   - 所有回答都来自用户添加的资料
   - 不会产生超出资料范围的回答

3. **精确引用 [1][2][3]**
   - 每个观点都标注来源编号
   - 点击引用 → 跳转到资料原文位置
   - 悬浮引用 → 显示原文预览卡片
   - 底部显示引用来源列表

4. **回答操作按钮**
   - [💾 保存到笔记] - 保存整个回答到 Notes
   - [📋 复制] - 复制回答内容
   - [👍] [👎] - 反馈回答质量

5. **对话历史**
   - 自动保存所有对话
   - 可滚动查看历史
   - 支持搜索历史对话

**引用预览卡片** (悬浮时显示):

```
┌─────────────────────────────────────────┐
│ [1] vLLM: PagedAttention 论文           │
├─────────────────────────────────────────┤
│ "...PagedAttention 将 KV cache 划分    │
│ 为固定大小的块，每个块存储固定数量的     │
│ token 的 key 和 value 向量..."          │
│                                         │
│ 📄 arXiv · 2023-09 · 第 3 页            │
│ [打开原文]                              │
└─────────────────────────────────────────┘
```

#### 3.2.3 右栏: Studio Panel (创意工作室)

> **NotebookLM 设计**: Studio 面板让你一键从资料生成各种内容，包括 Study Guide、Briefing Doc、FAQ、Timeline、Audio Overview

**这是 NotebookLM 最核心的差异化功能！**

**界面布局**:

```
┌─────────────────────────────────────────────────────────────────────┐
│                          🎨 Studio                                   │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  📝 Notes                                                           │
│  ─────────────────────────────────────────────────────────────────  │
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ + 添加笔记                                                   │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│  📌 技术对比分析                                          [✏️][🗑️] │
│      vLLM vs TensorRT 的核心差异...                                 │
│      今天 10:30                                                     │
│                                                                     │
│  📌 核心观点总结                                          [✏️][🗑️] │
│      PagedAttention 的关键创新点...                                 │
│      今天 10:15                                                     │
│                                                                     │
│  📌 选型建议                                              [✏️][🗑️] │
│      根据场景选择推理框架...                                        │
│      昨天                                                           │
│                                                                     │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━   │
│                                                                     │
│  🎯 一键生成                                                        │
│  ─────────────────────────────────────────────────────────────────  │
│                                                                     │
│  ┌──────────────────┐  ┌──────────────────┐                        │
│  │ 📋 Study Guide   │  │ 📄 Briefing Doc  │                        │
│  │                  │  │                  │                        │
│  │ 生成学习指南     │  │ 生成简报文档     │                        │
│  │ 含测验题和词汇表 │  │ 关键主题和总结   │                        │
│  └──────────────────┘  └──────────────────┘                        │
│                                                                     │
│  ┌──────────────────┐  ┌──────────────────┐                        │
│  │ ❓ FAQ           │  │ 📅 Timeline      │                        │
│  │                  │  │                  │                        │
│  │ 生成常见问答     │  │ 生成时间线       │                        │
│  │ 问题和答案列表   │  │ 事件按时间排列   │                        │
│  └──────────────────┘  └──────────────────┘                        │
│                                                                     │
│  ┌──────────────────────────────────────────┐                      │
│  │ 🎙️ Audio Overview                        │                      │
│  │                                          │                      │
│  │ 生成音频播客                              │                      │
│  │ 两位 AI 主持人讨论你的研究                │                      │
│  │                                          │                      │
│  │ [▶️ 播放] [⬇️ 下载]        时长: 8:32    │                      │
│  └──────────────────────────────────────────┘                      │
│                                                                     │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━   │
│                                                                     │
│  已生成的内容                                                        │
│  ─────────────────────────────────────────────────────────────────  │
│                                                                     │
│  🎙️ Audio Overview - LLM推理优化                        2 分钟前   │
│  📋 Study Guide - 推理框架对比学习                      10 分钟前   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**一键生成功能详解**:

| 功能                  | 说明     | 输出内容                                 |
| --------------------- | -------- | ---------------------------------------- |
| 📋 **Study Guide**    | 学习指南 | 简答题测验、答案解析、论述题、术语词汇表 |
| 📄 **Briefing Doc**   | 简报文档 | 执行摘要、主要主题、关键引用、结论       |
| ❓ **FAQ**            | 常见问答 | 基于资料生成的问题和答案列表             |
| 📅 **Timeline**       | 时间线   | 按时间顺序排列的事件                     |
| 🎙️ **Audio Overview** | 音频播客 | 两位 AI 主持人讨论研究内容 (5-15分钟)    |

**Study Guide 生成示例**:

```
┌─────────────────────────────────────────────────────────────────────┐
│  📋 Study Guide: LLM 推理优化技术                                    │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  📝 简答题测验                                                       │
│  ─────────────────────────────────────────────────────────────────  │
│                                                                     │
│  1. PagedAttention 解决了什么核心问题？                              │
│     答案: 解决了 LLM 推理中 KV cache 的内存碎片问题...               │
│                                                                     │
│  2. vLLM 和 TensorRT-LLM 的主要区别是什么？                         │
│     答案: vLLM 侧重内存效率，TensorRT-LLM 侧重硬件加速...            │
│                                                                     │
│  3. Speculative Decoding 的原理是什么？                              │
│     答案: 使用小模型预测，大模型验证，加速自回归生成...              │
│                                                                     │
│  📖 论述题                                                           │
│  ─────────────────────────────────────────────────────────────────  │
│                                                                     │
│  1. 分析 LLM 推理优化的三个主要技术方向及其适用场景                  │
│                                                                     │
│  2. 比较不同推理框架的技术路线，讨论未来发展趋势                     │
│                                                                     │
│  📚 术语词汇表                                                       │
│  ─────────────────────────────────────────────────────────────────  │
│                                                                     │
│  • PagedAttention: 一种将 KV cache 分页管理的注意力机制              │
│  • KV Cache: 存储 key-value 向量的缓存，用于自回归生成               │
│  • Speculative Decoding: 推测解码，使用小模型加速推理                │
│  • Continuous Batching: 连续批处理，动态管理请求批次                 │
│                                                                     │
│  ─────────────────────────────────────────────────────────────────  │
│  [📥 下载 PDF] [📋 复制] [✏️ 编辑]                                   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**Audio Overview 播放器**:

```
┌─────────────────────────────────────────────────────────────────────┐
│  🎙️ Audio Overview                                                   │
│  LLM 推理优化技术深度解析                                            │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                                                             │   │
│  │   🎧  ▶️ ━━━━━━━━━━━━━●━━━━━━━━━━━━━━━━━━━  🔊             │   │
│  │        2:34                              8:32               │   │
│  │                                                             │   │
│  │   [⏮️ -15s]  [▶️ 播放]  [⏭️ +15s]       [1x ▼]  [⬇️]      │   │
│  │                                                             │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│  📜 实时字幕                                                        │
│  ─────────────────────────────────────────────────────────────────  │
│                                                                     │
│  [Host A] 今天我们来聊聊 LLM 推理优化，这是一个非常热门的话题...     │
│                                                                     │
│  [Host B] 是的，特别是 vLLM 的 PagedAttention 技术，真的是          │
│           一个突破性的创新。它解决了内存碎片的问题...                 │
│                                                                     │
│  [Host A] 对，我看资料里提到，这个技术可以把显存利用率               │
│           提升到 95%，这在之前是不可想象的...                        │
│                                                                     │
│  ─────────────────────────────────────────────────────────────────  │
│                                                                     │
│  基于 5 个资料源生成 · 2025-11-29 10:30                             │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**笔记编辑器** (点击笔记时展开):

```
┌─────────────────────────────────────────────────────────────────────┐
│  📌 技术对比分析                                    [保存] [✕ 关闭] │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │ ## vLLM vs TensorRT-LLM 核心差异                            │   │
│  │                                                             │   │
│  │ ### 技术路线                                                 │   │
│  │ - **vLLM**: PagedAttention，侧重内存效率                    │   │
│  │ - **TensorRT-LLM**: CUDA 深度优化，侧重计算性能             │   │
│  │                                                             │   │
│  │ ### 性能对比                                                 │   │
│  │ | 指标 | vLLM | TensorRT-LLM |                              │   │
│  │ |------|------|--------------|                              │   │
│  │ | 吞吐 | 2.3k | 2.9k         |                              │   │
│  │ | 延迟 | 45ms | 32ms         |                              │   │
│  │                                                             │   │
│  │ ### 选型建议                                                 │   │
│  │ - 云端高吞吐 → TensorRT-LLM                                 │   │
│  │ - 快速迭代 → vLLM                                           │   │
│  │                                                             │   │
│  │ 来源: [1] vLLM论文 [2] TensorRT文档                         │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│  ─────────────────────────────────────────────────────────────────  │
│  创建: 今天 10:30 · 来自对话                                        │
│  [添加到 Study Guide] [添加到 Briefing Doc] [🗑️ 删除]              │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 4. 数据模型重设计

### 4.1 核心实体

```typescript
// 研究项目 (对应 NotebookLM 的 Notebook)
interface ResearchProject {
  id: string;
  name: string;
  description?: string;
  userId: string;

  // 资料
  sources: Source[];

  // 笔记
  notes: Note[];

  // 对话历史
  conversations: Conversation[];

  // 产出物
  outputs: Output[];

  createdAt: Date;
  updatedAt: Date;

  // 统计
  stats: {
    sourceCount: number;
    noteCount: number;
    messageCount: number;
  };
}

// 资料源
interface Source {
  id: string;
  projectId: string;

  // 资料类型
  type: "paper" | "github" | "news" | "blog" | "pdf" | "url" | "text";

  // 基本信息
  title: string;
  url?: string;
  content: string; // 原始内容

  // AI 分析结果
  analysis: {
    status: "pending" | "processing" | "completed" | "failed";
    summary?: string; // AI 摘要
    keyPoints?: string[]; // 关键要点
    entities?: Entity[]; // 提取的实体
    embeddings?: number[]; // 向量嵌入（用于 RAG）
  };

  // 元数据（根据类型不同）
  metadata: {
    authors?: string[];
    publishedAt?: Date;
    citations?: number;
    stars?: number; // GitHub
    // ... 其他
  };

  addedAt: Date;
}

// 笔记
interface Note {
  id: string;
  projectId: string;

  title: string;
  content: string; // Markdown 格式

  // 来源引用
  sourceRefs: {
    sourceId: string;
    quote?: string;
  }[];

  // 从对话保存
  fromMessageId?: string;

  createdAt: Date;
  updatedAt: Date;

  // 排序
  order: number;
}

// 对话
interface Conversation {
  id: string;
  projectId: string;

  messages: Message[];

  createdAt: Date;
}

interface Message {
  id: string;
  role: "user" | "assistant";
  content: string;

  // AI 回答的引用
  citations?: {
    sourceId: string;
    quote: string;
    confidence: number;
  }[];

  timestamp: Date;
}

// 产出物
interface Output {
  id: string;
  projectId: string;

  type: "podcast" | "report" | "chart" | "export";

  title: string;
  content: any; // 根据类型不同

  // 播客特有
  audioUrl?: string;
  duration?: number;

  createdAt: Date;
}
```

### 4.2 数据库迁移

```sql
-- 新增 research_projects 表
CREATE TABLE research_projects (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(255) NOT NULL,
  description TEXT,
  user_id UUID REFERENCES users(id),
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- 新增 project_sources 表
CREATE TABLE project_sources (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES research_projects(id) ON DELETE CASCADE,
  type VARCHAR(50) NOT NULL,
  title VARCHAR(500) NOT NULL,
  url TEXT,
  content TEXT,
  analysis_status VARCHAR(50) DEFAULT 'pending',
  analysis_result JSONB,
  metadata JSONB,
  embeddings vector(1536),  -- pgvector
  added_at TIMESTAMP DEFAULT NOW()
);

-- 新增 project_notes 表
CREATE TABLE project_notes (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES research_projects(id) ON DELETE CASCADE,
  title VARCHAR(255) NOT NULL,
  content TEXT,
  source_refs JSONB,
  from_message_id UUID,
  display_order INTEGER DEFAULT 0,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- 新增 project_conversations 表
CREATE TABLE project_conversations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES research_projects(id) ON DELETE CASCADE,
  created_at TIMESTAMP DEFAULT NOW()
);

-- 新增 conversation_messages 表
CREATE TABLE conversation_messages (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  conversation_id UUID REFERENCES project_conversations(id) ON DELETE CASCADE,
  role VARCHAR(20) NOT NULL,
  content TEXT NOT NULL,
  citations JSONB,
  created_at TIMESTAMP DEFAULT NOW()
);

-- 新增 project_outputs 表
CREATE TABLE project_outputs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES research_projects(id) ON DELETE CASCADE,
  type VARCHAR(50) NOT NULL,
  title VARCHAR(255),
  content JSONB,
  audio_url TEXT,
  duration INTEGER,
  created_at TIMESTAMP DEFAULT NOW()
);
```

---

## 5. API 设计

### 5.1 项目管理

```
POST   /api/v1/studio/projects              # 创建项目
GET    /api/v1/studio/projects              # 获取项目列表
GET    /api/v1/studio/projects/:id          # 获取项目详情
PATCH  /api/v1/studio/projects/:id          # 更新项目
DELETE /api/v1/studio/projects/:id          # 删除项目
```

### 5.2 资料管理

```
POST   /api/v1/studio/projects/:id/sources          # 添加资料
GET    /api/v1/studio/projects/:id/sources          # 获取资料列表
DELETE /api/v1/studio/projects/:id/sources/:sid     # 删除资料
POST   /api/v1/studio/projects/:id/sources/search   # 搜索资料（从外部源）
POST   /api/v1/studio/projects/:id/sources/upload   # 上传文件
```

### 5.3 AI 对话

```
POST   /api/v1/studio/projects/:id/chat             # 发送消息（支持流式）
GET    /api/v1/studio/projects/:id/conversations    # 获取对话历史
DELETE /api/v1/studio/projects/:id/conversations/:cid  # 删除对话
```

### 5.4 笔记管理

```
POST   /api/v1/studio/projects/:id/notes            # 创建笔记
GET    /api/v1/studio/projects/:id/notes            # 获取笔记列表
PATCH  /api/v1/studio/projects/:id/notes/:nid       # 更新笔记
DELETE /api/v1/studio/projects/:id/notes/:nid       # 删除笔记
POST   /api/v1/studio/projects/:id/notes/reorder    # 重排序
```

### 5.5 产出生成

```
POST   /api/v1/studio/projects/:id/outputs/podcast  # 生成播客
POST   /api/v1/studio/projects/:id/outputs/report   # 生成报告
POST   /api/v1/studio/projects/:id/outputs/chart    # 生成图表
POST   /api/v1/studio/projects/:id/outputs/export   # 导出
GET    /api/v1/studio/projects/:id/outputs          # 获取产出列表
```

---

## 6. 前端组件架构

```
frontend/app/studio/
├── page.tsx                           # 项目列表页
├── [projectId]/
│   └── page.tsx                       # 项目详情页
│
frontend/components/studio/
├── ProjectList/
│   ├── ProjectList.tsx               # 项目列表
│   ├── ProjectCard.tsx               # 项目卡片
│   └── CreateProjectDialog.tsx       # 创建对话框
│
├── ProjectWorkspace/
│   ├── ProjectWorkspace.tsx          # 主工作区（三栏布局）
│   ├── SourcesPanel/
│   │   ├── SourcesPanel.tsx          # 资料面板
│   │   ├── SourceItem.tsx            # 资料项
│   │   ├── AddSourceDialog.tsx       # 添加资料对话框
│   │   └── SourcePreview.tsx         # 资料预览
│   │
│   ├── ChatPanel/
│   │   ├── ChatPanel.tsx             # 对话面板
│   │   ├── MessageList.tsx           # 消息列表
│   │   ├── Message.tsx               # 消息组件
│   │   ├── Citation.tsx              # 引用组件
│   │   ├── ChatInput.tsx             # 输入框
│   │   └── SuggestedQuestions.tsx    # 建议问题
│   │
│   └── NotesPanel/
│       ├── NotesPanel.tsx            # 笔记面板
│       ├── NoteItem.tsx              # 笔记项
│       ├── NoteEditor.tsx            # 笔记编辑器
│       ├── OutputSection.tsx         # 产出区域
│       └── PodcastGenerator.tsx      # 播客生成器
│
└── common/
    ├── SearchSourceDialog.tsx        # 搜索资料对话框
    └── SourceBadge.tsx               # 资料类型徽章
```

---

## 7. 状态管理

```typescript
// stores/studioStore.ts

interface StudioState {
  // 当前项目
  currentProject: ResearchProject | null;

  // 资料
  sources: Source[];
  sourcesLoading: boolean;

  // 对话
  messages: Message[];
  isStreaming: boolean;

  // 笔记
  notes: Note[];
  activeNoteId: string | null;

  // 产出
  outputs: Output[];
  generatingOutput: boolean;
}

interface StudioActions {
  // 项目
  loadProject: (projectId: string) => Promise<void>;
  createProject: (data: CreateProjectInput) => Promise<string>;

  // 资料
  addSource: (source: AddSourceInput) => Promise<void>;
  removeSource: (sourceId: string) => Promise<void>;
  searchSources: (query: string, types: string[]) => Promise<SearchResult[]>;

  // 对话
  sendMessage: (content: string) => Promise<void>;

  // 笔记
  createNote: (content: string, title?: string) => Promise<void>;
  updateNote: (noteId: string, data: UpdateNoteInput) => Promise<void>;
  deleteNote: (noteId: string) => Promise<void>;
  saveToNote: (messageId: string) => Promise<void>;

  // 产出
  generatePodcast: () => Promise<void>;
  generateReport: () => Promise<void>;
  exportProject: (format: "pdf" | "md" | "docx") => Promise<void>;
}

export const useStudioStore = create<StudioState & StudioActions>(
  (set, get) => ({
    // ... 实现
  }),
);
```

---

## 8. 实施计划

### Phase 1: 基础架构 (Week 1)

| 任务                      | 工作量 | 优先级 |
| ------------------------- | ------ | ------ |
| 数据库迁移（新增表）      | 1d     | P0     |
| API 基础接口（项目 CRUD） | 1d     | P0     |
| 前端路由和基础布局        | 1d     | P0     |
| 项目列表页面              | 1d     | P1     |
| 创建项目对话框            | 0.5d   | P1     |

### Phase 2: 资料管理 (Week 2)

| 任务                      | 工作量 | 优先级 |
| ------------------------- | ------ | ------ |
| 资料添加（搜索/URL/上传） | 2d     | P0     |
| 资料分析服务              | 2d     | P0     |
| 资料面板 UI               | 1d     | P0     |
| 资料预览                  | 0.5d   | P1     |

### Phase 3: AI 对话 (Week 3)

| 任务                     | 工作量 | 优先级 |
| ------------------------ | ------ | ------ |
| RAG 对话服务（基于资料） | 3d     | P0     |
| 对话面板 UI              | 1d     | P0     |
| 引用标注和预览           | 1d     | P0     |
| 建议问题生成             | 0.5d   | P1     |

### Phase 4: 笔记与产出 (Week 4)

| 任务                 | 工作量 | 优先级 |
| -------------------- | ------ | ------ |
| 笔记 CRUD            | 1d     | P0     |
| 笔记编辑器           | 1d     | P0     |
| 保存到笔记功能       | 0.5d   | P0     |
| 播客生成（对接 TTS） | 2d     | P1     |
| 报告生成             | 1d     | P1     |
| 导出功能             | 1d     | P2     |

---

## 9. 成功指标

### 核心指标

| 指标            | 目标    | 说明         |
| --------------- | ------- | ------------ |
| 项目创建数      | 100+/天 | 用户活跃度   |
| 平均资料数/项目 | 5+      | 资料丰富度   |
| 对话轮次/项目   | 10+     | 深度使用     |
| 笔记创建率      | 30%+    | 知识沉淀     |
| 播客生成率      | 10%+    | 特色功能使用 |

### 体验指标

| 指标          | 目标   | 说明             |
| ------------- | ------ | ---------------- |
| 首次对话时间  | <3min  | 快速上手         |
| AI 回答准确率 | >90%   | 基于资料的准确性 |
| 用户满意度    | NPS>50 | 整体体验         |

---

## 10. 总结

### 新设计 vs 旧设计

| 维度         | 旧设计         | 新设计                     |
| ------------ | -------------- | -------------------------- |
| **核心概念** | 搜索工具       | 研究项目                   |
| **用户流程** | 搜索 → 看结果  | 建项目 → 加资料 → 深度研究 |
| **信息组织** | 散乱的搜索结果 | 项目化知识管理             |
| **AI 定位**  | 通用 AI 问答   | 基于你的资料的专属助手     |
| **产出形式** | 报告（很少用） | 笔记 + 播客 + 报告         |
| **记忆性**   | 无状态         | 项目内持久化               |

### 核心改进

1. **建立"项目"概念** - 让用户的研究有组织、可持续
2. **资料优先** - AI 分析基于用户添加的资料，而不是通用知识
3. **引用可追溯** - 每个观点都有明确来源
4. **知识沉淀** - 笔记功能帮助用户积累知识
5. **惊喜时刻** - 播客功能创造独特价值

---

**文档版本**: v4.0
**最后更新**: 2025-11-29
**下一步**: 团队评审 → 技术评审 → 开始开发
