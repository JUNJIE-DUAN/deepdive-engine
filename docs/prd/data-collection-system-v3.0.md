# 数据采集系统产品需求文档 v3.0

## 文档信息

- **文档版本**: v3.0
- **创建日期**: 2025-11-21
- **作者**: 产品设计
- **状态**: 待评审

---

## 一、产品概述

### 1.1 产品定位

打造一个**自动化、智能化、高质量**的多源数据采集系统，每天自动采集全球TOP内容，为DeepDive平台提供高质量的知识资源。

### 1.2 核心目标

| 内容类型    | 数据源示例                         | 日采集量目标 |
| ----------- | ---------------------------------- | ------------ |
| 📄 学术论文 | arXiv, PubMed, IEEE, ACL Anthology | 100-200篇    |
| 📝 技术博客 | Medium, Dev.to, Substack, 个人博客 | 50-100篇     |
| 🎬 技术视频 | YouTube, Bilibili, 3Blue1Brown     | 20-50个      |
| 📰 行业新闻 | TechCrunch, The Verge, HackerNews  | 50-100条     |
| 📊 研究报告 | Gartner, McKinsey, IDC, 企业白皮书 | 10-20份      |
| 🏛️ 政策文件 | 各国科技政策、法规、标准           | 5-10份       |
| 💻 开源项目 | GitHub Trending, Product Hunt      | 30-50个      |

**总计日采集量**: 265-530 条高质量内容

### 1.3 核心价值主张

- ✅ **完整性**：采集100%的原始数据，不丢失任何信息
- ✅ **准确性**：智能去重+质量评分，确保数据唯一且高质量
- ✅ **时效性**：每天自动采集，实时更新
- ✅ **可追溯**：完整的数据血缘关系，原始数据永久保存
- ✅ **智能化**：AI自动分析、分类、打标签、生成摘要

---

## 二、现状问题分析

### 2.1 当前存在的问题（来自用户反馈）

根据用户反馈，当前系统存在以下**致命问题**：

#### 问题1: 原始数据不完整 🔴 **严重**

- **现象**: `data_collection_raw_data` 集合中，各类数据只存储了极其基本的信息
- **影响**: 无法用于数据重新处理、审计和质量追溯
- **根因**: 采集时只提取了部分字段，未保存完整原始响应

#### 问题2: 缺少资源引用 🔴 **严重**

- **现象**: MongoDB 的 `data_collection_raw_data` 没有对 PostgreSQL Resource 的引用
- **影响**: 无法建立数据血缘关系，无法追溯原始数据
- **根因**: 数据模型设计缺陷，未建立双向引用

#### 问题3: 大量重复数据 🔴 **严重**

- **现象**: resource-xxx 数据集合存在大量重复，业务代码没有判重和去重
- **影响**: 数据库膨胀、用户体验差、推荐质量低
- **根因**: 缺少有效的去重机制

#### 问题4: 数据集合不全 🟡 **中等**

- **现象**: resource-xxx 数据集合不完整
- **影响**: 无法满足用户需求，数据覆盖面不足
- **根因**: 数据源不足、采集频率低

**结论**: 数据采集功能根本不能使用，需要**彻底重构**！

### 2.2 架构问题：Settings vs Collection

**当前架构**：

- `/admin/settings` 页面包含 3 个标签：Collection、Whitelist、Quality
- Collection 功能过于简单，只有规则管理，缺少监控和历史

**问题**：

1. Settings 页面承载过多功能，变得臃肿
2. Collection 功能不完整，无法支撑日常运营
3. 缺少独立的数据采集工作台

**解决方案**：

- 保留 `/admin/settings` 作为系统配置入口
- 新建 `/data-collection` 作为独立的数据采集中心

---

## 三、产品目标

### 3.1 业务目标

| 指标           | 当前值 | 目标值（3个月） |
| -------------- | ------ | --------------- |
| **数据完整性** | ~30%   | >95%            |
| **去重准确率** | 0%     | >98%            |
| **采集成功率** | ~50%   | >95%            |
| **平均质量分** | 未知   | >8.0/10         |
| **日采集量**   | ~100条 | 500+条          |
| **采集数据源** | 3个    | 15+个           |

### 3.2 用户目标

**目标用户**: DeepDive 平台管理员、内容运营人员

**核心诉求**:

1. 能够轻松配置和管理多个数据源
2. 实时监控采集进度和状态
3. 快速发现和解决质量问题
4. 自动化运营，减少人工干预

---

## 四、功能设计

### 4.1 页面架构

```
/data-collection （数据采集中心）
├── /dashboard          - 采集总览仪表盘
├── /sources           - 数据源管理
├── /scheduler         - 采集计划管理
├── /monitor           - 实时监控
├── /quality           - 数据质量管理
└── /history           - 采集历史

/admin/settings        - 系统设置（简化）
├── /whitelist         - 域名白名单
├── /quality-rules     - 质量规则
└── /system            - 系统配置
```

### 4.2 核心功能详解

#### 功能1: 采集总览仪表盘 (`/data-collection/dashboard`)

**功能描述**: 提供数据采集的全局视图和关键指标

**核心指标卡片**:

- 今日采集数量（对比昨日）
- 采集成功率（7日趋势）
- 去重率（7日趋势）
- 平均质量分（分布图）

**数据可视化**:

- 7天采集趋势图（折线图）
- 按数据源分类统计（饼图+卡片）
- 实时任务状态（进度条）

**快速操作**:

- 手动触发采集
- 停止/重启任务
- 查看日志

#### 功能2: 数据源管理 (`/data-collection/sources`)

**功能描述**: 管理所有数据源的配置和状态

**数据源列表**:

- 支持多维度筛选（类型、状态、成功率）
- 批量操作（批量启用/暂停/删除）
- 快速搜索

**添加数据源向导**:

```
步骤1: 选择数据源类型
  - 学术论文 (arXiv, PubMed, IEEE...)
  - 技术博客 (Medium, RSS...)
  - 视频平台 (YouTube, Bilibili...)
  - 新闻网站 (URL列表)
  - 研究报告 (PDF URL)
  - 政策文件 (政府网站)

步骤2: 配置连接信息
  - 数据源URL
  - API Key（如需要）
  - 认证方式（API、OAuth、Cookie）

步骤3: 设置采集规则
  - 关键词过滤
  - 分类选择
  - 语言选择
  - 最小质量阈值

步骤4: 配置采集频率
  - 预设模板（每天、每12小时、每周）
  - Cron表达式（高级用户）

步骤5: 去重策略
  - URL去重
  - 标题相似度去重（可配置阈值）
  - 内容指纹去重

步骤6: 高级选项
  - 并发数控制
  - 超时设置
  - 重试策略
  - User-Agent、Proxy配置

步骤7: 测试连接
  - 实时测试数据源连接
  - 预览采集结果
  - 调整配置
```

#### 功能3: 采集计划管理 (`/data-collection/scheduler`)

**功能描述**: 管理定时采集任务和调度规则

**今日计划时间轴**:

- 可视化展示今日所有计划的执行时间
- 标注已完成/进行中/等待/失败状态
- 点击可查看详情

**采集计划列表**:

- 计划名称、数据源、执行时间
- 状态（活跃/暂停/失败）
- 下次执行时间
- 预计采集数量

**创建计划**:

- 选择多个数据源（批量采集）
- 设置采集时间（支持多个时间点）
- 采集数量限制
- 优先级设置
- 失败处理策略（自动重试、邮件通知）

#### 功能4: 实时监控 (`/data-collection/monitor`)

**功能描述**: 实时监控采集任务的执行状态

**系统状态**:

- CPU、内存、网络使用率
- 活跃任务数、队列长度、平均等待时间

**正在执行的任务**:

- 任务名称、进度条（百分比）
- 当前状态（正在处理第X条...）
- 统计信息（已采集、已去重、失败）
- 预计完成时间
- 操作按钮（暂停、停止、查看详情）

**实时日志流**:

- WebSocket实时推送日志
- 日志级别筛选（INFO、WARN、ERROR）
- 搜索和高亮
- 导出日志

#### 功能5: 数据质量管理 (`/data-collection/quality`)

**功能描述**: 监控和管理数据质量问题

**质量概览**:

- 平均质量分（0-10分）
- 完整性、准确性、时效性、可用性评分

**质量问题列表**:

- 高/中/低优先级分类
- 问题类型（标题缺失、可能重复、元数据不完整）
- 检测时间、影响资源数
- 修复建议

**问题处理**:

- 自动修复（重新采集、补充元数据）
- 手动处理（合并重复、删除资源）
- 批量处理

**质量趋势分析**:

- 过去30天质量分变化趋势
- 问题类型分布
- 修复率统计

#### 功能6: 采集历史 (`/data-collection/history`)

**功能描述**: 查看历史采集记录和统计

**历史记录表格**:

- 执行时间、数据源、任务类型
- 采集数量、成功/失败/去重
- 执行时长、质量分
- 操作（查看详情、重新执行、导出报告）

**统计报表**:

- 按日/周/月统计
- 数据源对比分析
- 成功率趋势
- 导出Excel/PDF

---

## 五、数据质量保障

### 5.1 质量评分体系

**总分计算**: (完整性×40% + 准确性×30% + 时效性×20% + 可用性×10%) / 10

#### 完整性评分 (40%)

- 标题: 10分（必须非空且 >10字符）
- 内容: 10分（必须 >100字符）
- 作者: 10分（至少1个）
- 时间: 5分（publishedAt非空）
- 元数据: 5分（有分类、标签等）

#### 准确性评分 (30%)

- URL有效: 10分（HTTP 200）
- 格式正确: 10分（JSON/HTML/PDF可解析）
- 分类准确: 10分（AI分类置信度 >0.8）

#### 时效性评分 (20%)

- 发布时间: 10分（≤7天: 10分, ≤30天: 8分, >30天: 5分）
- 采集及时: 10分（发布后24h内采集: 10分）

#### 可用性评分 (10%)

- PDF可访问: 5分
- 图片完整: 5分

### 5.2 质量问题类型

| 问题类型     | 严重程度 | 自动修复 | 检测方式   |
| ------------ | -------- | -------- | ---------- |
| 标题缺失     | 高       | 是       | 字段检查   |
| 内容为空     | 高       | 是       | 字段检查   |
| 可能重复     | 中       | 否       | 相似度检测 |
| 元数据不完整 | 中       | 是       | 字段检查   |
| URL失效      | 中       | 否       | HTTP检查   |
| 分类错误     | 低       | 是       | AI重新分类 |

---

## 六、去重策略

### 6.1 多层去重机制

```
第1层: URL哈希去重（最快）
  ├─ 规范化URL（去除utm参数、hash等）
  ├─ 计算MD5哈希
  ├─ Redis查询O(1)
  └─ 相似度: 1.0（完全匹配）

第2层: 标题相似度去重
  ├─ 计算MinHash签名
  ├─ LSH快速检索
  ├─ Levenshtein距离精确匹配
  └─ 阈值: 0.85（可配置）

第3层: 内容指纹去重
  ├─ 计算SimHash（64位）
  ├─ 汉明距离比较
  └─ 阈值: ≤3位差异

第4层: 作者+时间去重（学术论文）
  ├─ 相同作者 + 相同发布日期
  └─ 标记为可疑重复
```

### 6.2 去重决策

- **相似度 ≥ 0.95**: 自动跳过，记录为重复
- **0.7 ≤ 相似度 < 0.95**: 标记为可疑重复，人工审核
- **相似度 < 0.7**: 视为新资源，正常处理

---

## 七、非功能需求

### 7.1 性能要求

| 指标         | 目标值      |
| ------------ | ----------- |
| 采集速度     | ≥50条/分钟  |
| 去重检测     | <100ms/条   |
| 质量评分     | <200ms/条   |
| AI增强       | <2s/条      |
| 页面加载     | <2s（首屏） |
| 实时推送延迟 | <500ms      |

### 7.2 可靠性要求

- 系统可用性: ≥99.5%
- 数据不丢失: 100%（MongoDB备份）
- 失败重试: 自动重试3次
- 任务恢复: 支持断点续采

### 7.3 安全要求

- API Key加密存储
- 数据传输HTTPS加密
- 访问权限控制（RBAC）
- 敏感信息脱敏

---

## 八、技术栈

### 8.1 前端技术

- **框架**: Next.js 14 + React 18
- **UI组件**: shadcn/ui + TailwindCSS
- **状态管理**: Zustand
- **数据获取**: TanStack Query
- **图表**: Recharts
- **实时通信**: WebSocket

### 8.2 后端技术

- **框架**: NestJS 10
- **ORM**: Prisma (PostgreSQL)
- **NoSQL**: MongoDB
- **缓存**: Redis
- **任务队列**: BullMQ
- **爬虫**: Playwright + Cheerio

### 8.3 AI服务

- **框架**: FastAPI (Python)
- **AI引擎**: Grok API (首选) / OpenAI (备用)
- **向量化**: sentence-transformers
- **向量库**: Qdrant

---

## 九、开发计划

### Phase 1: 基础架构优化 (2周)

- Week 1: 数据模型重构、双向引用
- Week 2: 去重引擎开发

### Phase 2: 数据源扩展 (2周)

- Week 3: 新增5个爬虫
- Week 4: 爬虫优化和测试

### Phase 3: 任务调度系统 (1周)

- Week 5: BullMQ集成、任务监控

### Phase 4: 数据质量保障 (1周)

- Week 6: 质量评估、问题检测

### Phase 5: UI开发 (2周)

- Week 7: Dashboard、Sources、Scheduler
- Week 8: Monitor、Quality、History

### Phase 6: 测试和上线 (1周)

- Week 9: 全面测试、部署上线

**总计**: 9周（约2.5个月）

---

## 十、成功指标

| 里程碑           | 验收标准                     |
| ---------------- | ---------------------------- |
| **M1: 数据完整** | MongoDB中原始数据完整性 >95% |
| **M2: 无重复**   | 去重准确率 >98%              |
| **M3: 高质量**   | 平均质量分 >8.0              |
| **M4: 大规模**   | 日采集量 >500条              |
| **M5: 多数据源** | 支持15+个数据源              |
| **M6: 稳定运行** | 采集成功率 >95%              |

---

## 十一、风险与应对

| 风险        | 影响 | 概率 | 应对措施                     |
| ----------- | ---- | ---- | ---------------------------- |
| 反爬虫限制  | 高   | 高   | 代理池、User-Agent轮换、限速 |
| API配额限制 | 中   | 中   | 多账号轮换、降低频率         |
| 数据源变更  | 中   | 中   | 监控告警、快速适配           |
| 性能瓶颈    | 高   | 低   | 分布式部署、队列优化         |
| 数据合规性  | 高   | 低   | 白名单机制、人工审核         |

---

## 附录

### A. 参考文档

- [数据采集技术架构](../data-management/architecture.md)
- [数据模型设计](../data-management/data-model.md)
- [实施路线图](../data-management/implementation-roadmap.md)

### B. 变更历史

- 2025-11-21: v3.0初始版本，完整重构

### C. 审批记录

- [ ] 产品负责人
- [ ] 技术负责人
- [ ] 项目经理
